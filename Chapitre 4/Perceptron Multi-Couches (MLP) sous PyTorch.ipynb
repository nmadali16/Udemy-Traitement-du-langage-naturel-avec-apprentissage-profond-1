{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyML8/8jYYiiEMxnG3yAuHgA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["\n","Dans ce lab, nous explorerons l'utilisation de PyTorch, une bibliothèque d'apprentissage automatique populaire, pour construire et entraîner un Perceptron Multi-Couches (MLP) pour la classification binaire. Un MLP est un type de réseau de neurones artificiels composé de plusieurs couches de neurones, utilisé pour résoudre une variété de problèmes, y compris la classification.\n","\n","Nous aborderons les étapes suivantes :\n","\n","1. **Génération de Données Aléatoires** : Nous commencerons par générer un ensemble de données synthétiques pour notre problème de classification binaire. Ces données seront utilisées pour entraîner notre modèle.\n","\n","```python\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","# Générer des données aléatoires\n","np.random.seed(0)\n","X = np.random.rand(100, 2)  # 100 échantillons, 2 caractéristiques\n","y = (X[:, 0] + X[:, 1] > 1).astype(np.float32)  # Classification binaire basée sur une condition simple\n","\n","# Convertir les données en tenseurs PyTorch\n","X = torch.Tensor(X)\n","y = torch.Tensor(y)\n","```\n","\n","2. **Construction du Modèle MLP** : Nous définirons la structure du réseau de neurones en utilisant PyTorch. Notre MLP aura une couche cachée et une couche de sortie pour la classification binaire.\n","\n","```python\n","# Définir le modèle MLP\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(2, 3)  # Taille d'entrée : 2, Taille de sortie : 3\n","        self.fc2 = nn.Linear(3, 1)  # Taille d'entrée : 3, Taille de sortie : 1\n","\n","    def forward(self, x):\n","        x = torch.sigmoid(self.fc1(x))\n","        x = torch.sigmoid(self.fc2(x))\n","        return x\n","\n","# Initialiser le modèle\n","model = MLP()\n","```\n","\n","3. **Définition de la Fonction de Perte et de l'Optimiseur** : Nous spécifierons la fonction de perte qui mesure l'écart entre les prédictions du modèle et les étiquettes réelles. De plus, nous choisirons un optimiseur pour ajuster les poids du réseau lors de l'entraînement.\n","\n","```python\n","# Définir la fonction de perte et l'optimiseur\n","criterion = nn.BCELoss()  # Perte de l'entropie croisée binaire\n","optimizer = optim.SGD(model.parameters(), lr=0.1)  # Descente de gradient stochastique\n","```\n","\n","4. **Entraînement du Modèle** : Nous entraînerons le modèle sur nos données générées, en ajustant les poids du réseau pour minimiser la fonction de perte.\n","\n","```python\n","# Entraîner le modèle\n","for epoch in range(1000):\n","    optimizer.zero_grad()  # Réinitialiser les gradients\n","    outputs = model(X)  # Passe avant\n","    loss = criterion(outputs, y.view(-1, 1))  # Calculer la perte\n","    loss.backward()  # Rétropropagation\n","    optimizer.step()  # Mettre à jour les poids\n","\n","    if (epoch+1) % 100 == 0:\n","        print(f'Époque [{epoch+1}/1000], Perte: {loss.item():.4f}')\n","```\n","\n","5. **Évaluation et Test du Modèle** : Nous testerons le modèle sur un ensemble de données de test pour évaluer sa performance.\n","\n","```python\n","# Tester le modèle\n","with torch.no_grad():\n","    test_data = torch.Tensor([[0.2, 0.8], [0.8, 0.2]])\n","    predictions = model(test_data)\n","    print(f'Prédictions : {predictions}')\n","```\n","\n","6. **Sauvegarde du Modèle** : Enfin, nous sauvegarderons les poids du modèle pour une utilisation future.\n","\n","```python\n","# Sauvegarder le modèle\n","torch.save(model.state_dict(), 'mlp_model.pth')\n","```\n"],"metadata":{"id":"zpoCm256T1Qk"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np"],"metadata":{"id":"SidyLpWJTS9k","executionInfo":{"status":"ok","timestamp":1698346273825,"user_tz":-120,"elapsed":7121,"user":{"displayName":"nabil bcom","userId":"04169804032469069549"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Générer des données aléatoires\n","np.random.seed(0)\n","X = np.random.rand(100, 2)  # 100 échantillons, 2 caractéristiques\n","y = (X[:, 0] + X[:, 1] > 1).astype(np.float32)  # Classification binaire basée sur une condition simple\n","\n","# Convertir les données en tenseurs PyTorch\n","X = torch.from_numpy(X).float().cuda()\n","y = torch.from_numpy(y).long().cuda()"],"metadata":{"id":"fAfSULb8TUYN","executionInfo":{"status":"ok","timestamp":1698346544032,"user_tz":-120,"elapsed":2,"user":{"displayName":"nabil bcom","userId":"04169804032469069549"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["\n","# Définir le modèle MLP\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(2, 3)  # Taille d'entrée : 2, Taille de sortie : 3\n","\n","        self.fc2 = nn.Linear(3, 1)  # Taille d'entrée : 3, Taille de sortie : 1\n","\n","    def forward(self, x):\n","        z =self.fc1(x)\n","        #print(x.shape)\n","        x = torch.sigmoid(self.fc2(z))\n","        return x,z"],"metadata":{"id":"flna4NTRTVgE","executionInfo":{"status":"ok","timestamp":1698346862615,"user_tz":-120,"elapsed":561,"user":{"displayName":"nabil bcom","userId":"04169804032469069549"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["\n","# Initialiser le modèle\n","model = MLP().cuda()"],"metadata":{"id":"uLdbvLchTW6s","executionInfo":{"status":"ok","timestamp":1698346863937,"user_tz":-120,"elapsed":2,"user":{"displayName":"nabil bcom","userId":"04169804032469069549"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Définir la fonction de perte et l'optimiseur\n","criterion = nn.BCELoss()  # Perte de l'entropie croisée binaire\n","optimizer = optim.SGD(model.parameters(), lr=0.1)  # Descente de gradient stochastique"],"metadata":{"id":"ELV3fqcpTYUy","executionInfo":{"status":"ok","timestamp":1698346604554,"user_tz":-120,"elapsed":5,"user":{"displayName":"nabil bcom","userId":"04169804032469069549"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Entraîner le modèle\n","for epoch in range(1000):\n","    optimizer.zero_grad()  # Réinitialiser les gradients\n","    outputs = model(X)  # Passe avant\n","    loss = criterion(outputs, y.float().view(-1, 1))  # Calculer la perte\n","    loss.backward()  # Rétropropagation\n","    optimizer.step()  # Mettre à jour les poids\n","\n","    if (epoch+1) % 100 == 0:\n","        print(f'Époque [{epoch+1}/1000], Perte: {loss.item():.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8JhP2m1iTak0","executionInfo":{"status":"ok","timestamp":1698346718336,"user_tz":-120,"elapsed":656,"user":{"displayName":"nabil bcom","userId":"04169804032469069549"}},"outputId":"08ec17be-9860-4349-c3cc-56489b76b462"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Époque [100/1000], Perte: 0.7439\n","Époque [200/1000], Perte: 0.7439\n","Époque [300/1000], Perte: 0.7439\n","Époque [400/1000], Perte: 0.7439\n","Époque [500/1000], Perte: 0.7439\n","Époque [600/1000], Perte: 0.7439\n","Époque [700/1000], Perte: 0.7439\n","Époque [800/1000], Perte: 0.7439\n","Époque [900/1000], Perte: 0.7439\n","Époque [1000/1000], Perte: 0.7439\n"]}]},{"cell_type":"code","source":["\n","# Tester le modèle\n","with torch.no_grad():\n","    test_data = torch.Tensor([[0.2, 0.8], [0.8, 0.2]]).cuda()\n","    predictions,hideen = model(test_data)\n","    print(f'Prédictions : {predictions}')\n","    print(f'hideen : {hideen}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T56f9Vv4TcZw","executionInfo":{"status":"ok","timestamp":1698346908813,"user_tz":-120,"elapsed":6,"user":{"displayName":"nabil bcom","userId":"04169804032469069549"}},"outputId":"b7449cec-6f77-4426-c571-be38db6b3914"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Prédictions : tensor([[0.4212],\n","        [0.5749]], device='cuda:0')\n","hideen : tensor([[ 0.1309, -0.4042, -0.2092],\n","        [-0.3615, -1.0540,  0.1796]], device='cuda:0')\n"]}]},{"cell_type":"code","source":["model.eval()"],"metadata":{"id":"7dlsinHIW2wK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"777DH9IYSW28"},"outputs":[],"source":["\n","# Sauvegarder le modèle\n","torch.save(model.state_dict(), 'mlp_model.pth')\n"]}]}