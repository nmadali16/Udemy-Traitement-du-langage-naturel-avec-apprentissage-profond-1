{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cd965aec-636e-4321-93cc-bb1224cad2bc",
      "metadata": {
        "id": "cd965aec-636e-4321-93cc-bb1224cad2bc"
      },
      "source": [
        "### Machine Translation with Seq2Seq Model in PyTorch\n",
        "\n",
        "# Machine Translation\n",
        "Machine translation (MT) refers to the automatic translation of text from one language to another using computational models. Neural Machine Translation (NMT) systems often use Seq2Seq architectures with encoder-decoder structures and attention mechanisms.\n",
        "\n",
        "## What is Machine Translation?\n",
        "\n",
        "Machine Translation (MT) is a subfield of Natural Language Processing (NLP) focused on the automatic translation of text or speech from one language to another. Given a source sentence $ X = (x_1, x_2, \\dots, x_n) $ in a source language, the goal is to generate a target sentence $ Y = (y_1, y_2, \\dots, y_m) $ in a target language that conveys the same meaning.\n",
        "\n",
        "In mathematical terms, the task can be modeled as finding the most probable translation $ Y^* $:\n",
        "\n",
        "$$\n",
        "Y^* = \\underset{Y}{\\text{argmax}} \\; P(Y|X)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ P(Y|X) $ is the conditional probability of the target sequence given the source sequence.\n",
        "\n",
        "Seq2Seq models break this task into two steps:\n",
        "1. **Encoding:** The source sentence $ X $ is encoded into a fixed-length context vector $ C $, which represents the meaning of the source sentence.\n",
        "2. **Decoding:** The target sentence $ Y $ is generated word-by-word based on the context vector $ C $ and the previously generated words.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "qcRHoM8JtoFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae33118-64e2-4ddc-bbd6-1a4d5f6ed955"
      },
      "id": "qcRHoM8JtoFR",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "3Ulmi9y01TDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10da8e6f-06ae-405f-dbfc-ca6b9c3ead94"
      },
      "id": "3Ulmi9y01TDQ",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.11.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6436eb4-7d5d-48d3-ab33-771ba55b98db",
      "metadata": {
        "id": "e6436eb4-7d5d-48d3-ab33-771ba55b98db"
      },
      "source": [
        "This lab demonstrates how to:\n",
        "1. Load a translation dataset from Hugging Face's `datasets` library.\n",
        "2. Create a PyTorch Dataset and DataLoader.\n",
        "3. Build a Seq2Seq model with an encoder-decoder architecture.\n",
        "4. Train the model.\n",
        "5. Evaluate the model using BLEU score."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3e55611-9c47-4255-8074-9e93d1e1b7ca",
      "metadata": {
        "id": "f3e55611-9c47-4255-8074-9e93d1e1b7ca"
      },
      "source": [
        "### 1. Load  Dataset\n",
        "The **ManyThings English-French dataset** is a popular dataset used for machine translation tasks, particularly for English-to-French translations. It is simple, lightweight, and primarily intended for beginner-level experimentation with machine translation models. Below is an explanation of its key aspects:\n",
        "\n",
        "**Content:**\n",
        "   - The dataset consists of parallel sentences, meaning that each English sentence is paired with its corresponding translation in French.\n",
        "   - The translations are often short, conversational, and simple, making it ideal for introductory machine translation tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "76b1b175-e7e2-45e5-9362-fd80e7b2e01e",
      "metadata": {
        "id": "76b1b175-e7e2-45e5-9362-fd80e7b2e01e"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"avitri/eng-fra\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlKWBvistv66",
        "outputId": "a78a6722-0da6-40c2-a082-fc8ad5ea6c9e"
      },
      "id": "OlKWBvistv66",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text'],\n",
              "        num_rows: 135842\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_ds=ds[\"train\"].train_test_split(0.1, seed=33)"
      ],
      "metadata": {
        "id": "YUcVdC0DttKX"
      },
      "id": "YUcVdC0DttKX",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data= split_ds['train'], split_ds['test']"
      ],
      "metadata": {
        "id": "ZvaD29vat2L-"
      },
      "id": "ZvaD29vat2L-",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0]['text'].split('\\t')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhnAW-ByuWhX",
        "outputId": "ba26f94e-24aa-4d3c-af64-429f9d9af1f8"
      },
      "id": "xhnAW-ByuWhX",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['They bought a box of cookies.', 'Ils ont acheté une boîte de biscuits.']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "e0f1e1d7-9f2c-4220-a5a0-cfc263ab1873",
      "metadata": {
        "id": "e0f1e1d7-9f2c-4220-a5a0-cfc263ab1873"
      },
      "outputs": [],
      "source": [
        "train_tokens_A=[token for sentence_pair in  train_data for token in sentence_pair['text'].split('\\t')[0].lower().split()]\n",
        "train_tokens_B=[token for sentence_pair in  train_data for token in sentence_pair['text'].split('\\t')[1].lower().split()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "vocab_A=Counter(train_tokens_A)\n",
        "vocab_B=Counter(train_tokens_B)\n",
        "\n"
      ],
      "metadata": {
        "id": "d4k_hJdKum1b"
      },
      "id": "d4k_hJdKum1b",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2i_A={k: (i+4) for i, (k,v) in enumerate(vocab_A.items())}\n",
        "w2i_B={k: (i+4) for i, (k,v) in enumerate(vocab_B.items())}"
      ],
      "metadata": {
        "id": "PbQT83V4vBBK"
      },
      "id": "PbQT83V4vBBK",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, k in enumerate(['<pad>','<bos>','<eos>','<unk>']):\n",
        "     w2i_A[k]=i\n",
        "     w2i_B[k]=i"
      ],
      "metadata": {
        "id": "-KXMDeafvI8s"
      },
      "id": "-KXMDeafvI8s",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(w2i_A),len(w2i_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bgv5MF8T0k7",
        "outputId": "d8651537-f143-4757-d48c-1acf84f08980"
      },
      "id": "9Bgv5MF8T0k7",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22603, 37272)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3704934e-0c0a-45e0-a534-fd4757190b64",
      "metadata": {
        "id": "3704934e-0c0a-45e0-a534-fd4757190b64"
      },
      "source": [
        "### 2. Dataset and Dataloader Creation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, train_data, w2i_A, w2i_B):\n",
        "        self.train_data = train_data\n",
        "        self.w2i_A = w2i_A\n",
        "        self.i2w_A = {v:k for (k,v) in w2i_A.items()}\n",
        "\n",
        "        self.w2i_B = w2i_B\n",
        "        self.i2w_B = {v:k for (k,v) in w2i_B.items()}\n",
        "    def __len__(self):\n",
        "        return len(self.train_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.train_data[idx]\n",
        "        sent_A, sent_B= sample['text'].split('\\t')\n",
        "\n",
        "\n",
        "        tokens_A=[w2i_A['<bos>']]\n",
        "        for token in sent_A.lower().split():\n",
        "          if token in w2i_A:\n",
        "            tokens_A.append(w2i_A[token])\n",
        "          else:\n",
        "             tokens_A.append(w2i_A['<unk>'])\n",
        "        tokens_A.append(w2i_A['<eos>'])\n",
        "\n",
        "        tokens_B=[w2i_B['<bos>']]\n",
        "        for token in sent_B.lower().split():\n",
        "          if token in w2i_B:\n",
        "            tokens_B.append(w2i_B[token])\n",
        "          else:\n",
        "             tokens_B.append(w2i_B['<unk>'])\n",
        "        tokens_B.append(w2i_B['<eos>'])\n",
        "\n",
        "        return tokens_A, tokens_B, len(tokens_A) , len(tokens_B)"
      ],
      "metadata": {
        "id": "_4Utp4u4vy0V"
      },
      "id": "_4Utp4u4vy0V",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=CustomDataset(train_data, w2i_A, w2i_B)\n",
        "test_dataset=CustomDataset(test_data, w2i_A, w2i_B)"
      ],
      "metadata": {
        "id": "ZfcpUB4qxTI0"
      },
      "id": "ZfcpUB4qxTI0",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmpdyV-6xYaX",
        "outputId": "ae20bf99-4605-4752-ee71-6414f41b4cd0"
      },
      "id": "dmpdyV-6xYaX",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 4, 5, 6, 7, 8, 9, 2], [1, 4, 5, 6, 7, 8, 9, 10, 2], 8, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjstLzNQxdDH",
        "outputId": "cfcfa11e-b968-4422-e64d-31a6f9a26601"
      },
      "id": "bjstLzNQxdDH",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1, 25, 35, 11722, 12, 3, 23, 2342, 8, 6837, 2],\n",
              " [1, 38, 158, 17229, 3, 17, 68, 6659, 9, 9384, 2],\n",
              " 11,\n",
              " 11)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def my_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Custom collate function for the DataLoader to handle variable-length sequences.\n",
        "    Pads input and target sequences to the maximum length in the batch.\n",
        "\n",
        "    Args:\n",
        "        batch (list of dicts): Each element contains `source_ids`, `source_mask`, and `target_ids`.\n",
        "\n",
        "    Returns:\n",
        "        dict: Padded and batched inputs and targets.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # Separate source and target sequences\n",
        "    source_ids = [torch.tensor(item[0]) for item in batch]\n",
        "    target_ids = [torch.tensor(item[1]) for item in batch]\n",
        "\n",
        "    source_lentghs=torch.tensor( [item[2] for item in batch])\n",
        "    target_lentghs = torch.tensor( [item[3] for item in batch])\n",
        "    # Pad the sequences to the maximum length in the batch\n",
        "    padded_source_ids = pad_sequence(source_ids, batch_first=True, padding_value=0)\n",
        "    padded_target_ids = pad_sequence(target_ids, batch_first=True, padding_value=0)\n",
        "\n",
        "\n",
        "    return padded_source_ids, padded_target_ids , source_lentghs, target_lentghs"
      ],
      "metadata": {
        "id": "qPBUekvbyM0-"
      },
      "id": "qPBUekvbyM0-",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn= my_collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "v03t7-w2x5Y3"
      },
      "id": "v03t7-w2x5Y3",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "757a3867-77d9-4960-9067-13d2cc38ed9b",
      "metadata": {
        "id": "757a3867-77d9-4960-9067-13d2cc38ed9b"
      },
      "source": [
        "### 3. Seq2Seq Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "1750f4b4-35fd-4802-85f4-9d12ccbd48ad",
      "metadata": {
        "id": "1750f4b4-35fd-4802-85f4-9d12ccbd48ad"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = torch.nn.functional.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, padding_idx_A, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=padding_idx_A)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "-dHXvxu5zsqu"
      },
      "id": "-dHXvxu5zsqu",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, num_embeddings_A, num_embeddings_B, hidden_size, padding_idx_A, padding_idx_B , dropout_rate=0.1):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "\n",
        "        self.encoder= EncoderRNN(num_embeddings_A, hidden_size, padding_idx_A, dropout_rate)\n",
        "        self.embedding = nn.Embedding(num_embeddings_B, hidden_size, padding_idx=padding_idx_B)\n",
        "\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, num_embeddings_B)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, input_tensor, target_tensor):\n",
        "\n",
        "        encoder_outputs, encoder_hidden=self.encoder(input_tensor)\n",
        "        batch_size,seq_len = target_tensor.shape\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(seq_len):\n",
        "\n",
        "            decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, attentions\n",
        "\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "3birAnS2zt_v"
      },
      "id": "3birAnS2zt_v",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "847c2771-3a61-4cdd-b511-42bcb7ed774f",
      "metadata": {
        "id": "847c2771-3a61-4cdd-b511-42bcb7ed774f"
      },
      "outputs": [],
      "source": [
        "# Initialize encoder and decoder\n",
        "num_embeddings_A=len(w2i_A)\n",
        "padding_idx_A=w2i_A['<pad>']\n",
        "\n",
        "\n",
        "num_embeddings_B=len(w2i_B)\n",
        "padding_idx_B=w2i_B['<pad>']\n",
        "\n",
        "hidden_size= 256\n",
        "dropout_rate=0.1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model= Seq2Seq(num_embeddings_A, num_embeddings_B ,hidden_size,padding_idx_A, padding_idx_B,dropout_rate).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(w2i_A),len(w2i_B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b9j_w_mKV6b",
        "outputId": "e7cbe503-6d46-4c85-87f2-6d333db9984c"
      },
      "id": "8b9j_w_mKV6b",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22603, 37272)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1p7bsrla6DGgtJNOAuqOmAn6FQ5YgrHDH\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KQl59wVKQ83",
        "outputId": "f8a3a8cd-0bac-439e-981c-9797b23433c3"
      },
      "id": "5KQl59wVKQ83",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1p7bsrla6DGgtJNOAuqOmAn6FQ5YgrHDH\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.text import Perplexity"
      ],
      "metadata": {
        "id": "X2cwO3yy0cSh"
      },
      "id": "X2cwO3yy0cSh",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss and Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_fn= torch.nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "perp=Perplexity().to(device)"
      ],
      "metadata": {
        "id": "Z2aypa4o0YKp"
      },
      "id": "Z2aypa4o0YKp",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1d042ea3-8e42-4faa-b417-dc5440858550",
      "metadata": {
        "id": "1d042ea3-8e42-4faa-b417-dc5440858550"
      },
      "source": [
        "### 4. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "386afa55-510b-4c0a-a338-94034b7f743e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "386afa55-510b-4c0a-a338-94034b7f743e",
        "outputId": "096ac295-74a9-4ff4-a221-a16854223cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 1911/1911 [03:03<00:00, 10.40batch/s, loss=2.02, perplexity=64.4]\n",
            "Epoch 1: 100%|██████████| 1911/1911 [03:03<00:00, 10.39batch/s, loss=1.17, perplexity=3.28]\n",
            "Epoch 2: 100%|██████████| 1911/1911 [03:02<00:00, 10.47batch/s, loss=0.857, perplexity=2.38]\n",
            "Epoch 3: 100%|██████████| 1911/1911 [03:03<00:00, 10.43batch/s, loss=0.67, perplexity=1.97]\n",
            "Epoch 4: 100%|██████████| 1911/1911 [03:06<00:00, 10.24batch/s, loss=0.556, perplexity=1.75]\n",
            "Epoch 5: 100%|██████████| 1911/1911 [03:02<00:00, 10.47batch/s, loss=0.478, perplexity=1.62]\n",
            "Epoch 6: 100%|██████████| 1911/1911 [03:02<00:00, 10.45batch/s, loss=0.423, perplexity=1.53]\n",
            "Epoch 7: 100%|██████████| 1911/1911 [03:02<00:00, 10.48batch/s, loss=0.385, perplexity=1.47]\n",
            "Epoch 8: 100%|██████████| 1911/1911 [03:02<00:00, 10.49batch/s, loss=0.354, perplexity=1.43]\n",
            "Epoch 9: 100%|██████████| 1911/1911 [03:01<00:00, 10.51batch/s, loss=0.331, perplexity=1.4]\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "import numpy as np\n",
        "n_epochs=10\n",
        "for epoch in range(n_epochs):\n",
        "  running_perplexity=[]\n",
        "  running_loss=[]\n",
        "  with tqdm.tqdm(train_dataloader, unit='batch') as tepoch:\n",
        "    for batch in tepoch:\n",
        "      tepoch.set_description(f'Epoch {epoch}')\n",
        "\n",
        "      padded_source_ids, padded_target_ids , source_lentghs, target_lentghs = batch\n",
        "      padded_source_ids, padded_target_ids =padded_source_ids.to(device).long(), padded_target_ids.to(device).long()\n",
        "\n",
        "      # Zero your gradients for every batch!\n",
        "      optimizer.zero_grad()\n",
        "      outputs, attentions =model(padded_source_ids, padded_target_ids)\n",
        "\n",
        "      batch_size, seq_len, vocab_size = outputs.shape\n",
        "\n",
        "      outputs = outputs[:,:-1,:].reshape(-1, vocab_size)\n",
        "      targets = padded_target_ids[:,1:].reshape(-1)\n",
        "\n",
        "      # Create a mask for non-padding tokens\n",
        "      mask = targets != 0\n",
        "\n",
        "      # Apply mask to filter out padding tokens\n",
        "      filtered_outputs = outputs[mask]\n",
        "      filtered_targets = targets[mask]\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      perplexity = perp(outputs.reshape(batch_size, (seq_len-1), vocab_size), targets.reshape(batch_size, (seq_len-1)))\n",
        "\n",
        "      running_perplexity.append(perplexity.item())\n",
        "      running_loss.append(loss.item())\n",
        "      tepoch.set_postfix(loss=np.mean(running_loss), perplexity = np.mean(running_perplexity) )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'pretrained_mt.pth')"
      ],
      "metadata": {
        "id": "XkiEdene3PTp"
      },
      "id": "XkiEdene3PTp",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('pretrained_mt.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ0dMTWIKOVk",
        "outputId": "ad4fbf04-c7a4-486b-ac05-fdcf7e143b52"
      },
      "id": "dJ0dMTWIKOVk",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-30c48d22b986>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('pretrained_mt.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "1f26f645-ec14-4c0c-b476-f31b3c4e1768",
      "metadata": {
        "id": "1f26f645-ec14-4c0c-b476-f31b3c4e1768"
      },
      "outputs": [],
      "source": [
        "#from nltk.translate.bleu_score import sentence_bleu"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}