{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67ff562-efe1-405d-9eb5-ebdc7f5c7650",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier for Text Classification\n",
    "\n",
    "### 1. **Introduction to Naive Bayes**\n",
    "\n",
    "Naive Bayes is a probabilistic classifier based on **Bayes' Theorem**. It is called \"naive\" because it assumes that the features (words in our case) are conditionally independent given the class label. Despite this strong assumption, Naive Bayes performs surprisingly well, especially in text classification tasks.\n",
    "\n",
    "### 2. **Bayes' Theorem**\n",
    "\n",
    "At the heart of the Naive Bayes classifier is **Bayes' Theorem**, which describes the probability of a class $C$ given a set of features $X$. The theorem is expressed as:\n",
    "\n",
    "$$\n",
    "P(C|X) = \\frac{P(X|C) \\cdot P(C)}{P(X)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $P(C|X)$ is the **posterior** probability of class $C$ given the features $X$.\n",
    "- $P(X|C)$ is the **likelihood** of observing features $X$ given the class $C$.\n",
    "- $P(C)$ is the **prior** probability of the class $C$.\n",
    "- $P(X)$ is the **evidence** or the probability of observing the features $X$ (which remains constant for all classes).\n",
    "\n",
    "### 3. **Simplification Using Naive Assumption**\n",
    "\n",
    "In the case of Naive Bayes, we make the assumption that the features are conditionally independent, given the class. This means that the probability of a feature $x_1, x_2, ..., x_n$ occurring together is the product of the individual probabilities of each feature. This simplifies our likelihood term:\n",
    "\n",
    "$$\n",
    "P(X|C) = P(x_1, x_2, ..., x_n | C) = \\prod_{i=1}^{n} P(x_i | C)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $x_1, x_2, ..., x_n$ are the features (in our case, the words in the document).\n",
    "- $P(x_i | C)$ is the probability of feature $x_i$ occurring given class $C$.\n",
    "\n",
    "Thus, the posterior probability becomes:\n",
    "\n",
    "$$\n",
    "P(C|X) = \\frac{P(C) \\cdot \\prod_{i=1}^{n} P(x_i | C)}{P(X)}\n",
    "$$\n",
    "\n",
    "We can ignore $P(X)$ because it is constant for all classes and doesnâ€™t affect the decision of which class is most likely. Therefore, we only need to compute:\n",
    "\n",
    "$$\n",
    "P(C|X) \\propto P(C) \\cdot \\prod_{i=1}^{n} P(x_i | C)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f1e503-cb98-4fc8-bdea-e4fd77d9faec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nmadali/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nmadali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "train_data, test_data = datasets.load_dataset(\"imdb\", split=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172b78e2-d754-419f-b611-59668b2d6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "  def __init__(self, stop_words, puncts, truncation_size=256  ):\n",
    "      \n",
    "    self.stop_words=stop_words\n",
    "    self.puncts=puncts\n",
    "    self.df = {}\n",
    "    self.truncation_size=truncation_size\n",
    "  def format_string(self, text):\n",
    "      tokens=[ token for token  in text.lower().split() if not ((token in self.stop_words) or  (token in self.puncts))   ]\n",
    "      return tokens  \n",
    "      \n",
    "  def tokenize(self, text, truncation=False):\n",
    "      tokens=self.format_string(text)\n",
    "      tmp=[]\n",
    "      for token in tokens:\n",
    "          if token in self.w2i :\n",
    "              tmp.append(self.w2i[token])\n",
    "          else:\n",
    "              tmp.append(self.w2i['<unk>'])\n",
    "              \n",
    "      if truncation:\n",
    "          tmp=tmp[: self.truncation_size]\n",
    "          output= np.ones(self.truncation_size)*self.w2i['<pad>']\n",
    "          output[:len(tmp)]=tmp\n",
    "          return list(output)\n",
    "      else:\n",
    "          return tmp\n",
    "  def detokenize(self, idxs):\n",
    "      words=[self.i2w[idx] for idx in idxs]  \n",
    "      \n",
    "      return ''.join(word+' ' for word in words )\n",
    "  def fit(self, train_text):\n",
    "    for text in train_text:\n",
    "        tokens=set(self.format_string(text))\n",
    "        for token in tokens:\n",
    "            if token in self.df:\n",
    "                self.df[token]+=1\n",
    "            else: \n",
    "                self.df[token]=1\n",
    "    self.df['<unk>']=1\n",
    "    self.df['<pad>']=1\n",
    "\n",
    "    \n",
    "    \n",
    "    self.w2i = { k:idx for idx, (k,v) in enumerate(self.df.items())}\n",
    "    self.i2w = { v:k for (k,v) in  self.w2i .items() }\n",
    "\n",
    "    self.idf=np.zeros(len(self.df))\n",
    "    for (k,v) in self.w2i.items():\n",
    "        self.idf[v]=np.log((1+len(train_text))/(1+self.df[k]))  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3978c0e6-1a83-4249-95de-2db274a54d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text=[sample['text'] for sample in train_data]\n",
    "train_label=[sample['label'] for sample in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3796f68d-4411-4124-926f-fce061e92cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text=[sample['text'] for sample in test_data]\n",
    "test_label=[sample['label'] for sample in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7d52f1-45c9-4114-9c91-51a42b7c107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= stopwords.words('english')\n",
    "puncts=  [punt for punt in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a00b52d6-1479-4729-9c83-0d2f45560605",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(stop_words , puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afdd1d0c-57f6-41a6-b29e-72403c623fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb7835f-a5e5-42a8-b306-f2e58a1888fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251445"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4391ca38-8ad4-47ca-832f-aa60ea7f0a6f",
   "metadata": {},
   "source": [
    "### 4. **Class Probabilities**\n",
    "\n",
    "For a given class $C$, the class probability $P(C)$ is simply the relative frequency of that class in the training data. If we have a dataset with $N$ total samples and $N_C$ samples of class $C$, the class probability is:\n",
    "\n",
    "$$\n",
    "P(C) = \\frac{N_C}{N}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629b0a7e-8906-46e8-afca-c8653f1eaef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['text'][0],train_data['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6c4f0aa-bb4b-40c2-a7bf-4b012df4b8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_data['label']),1-np.mean(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5284454-82c7-429a-ab2d-7d60ac7507af",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_prob={}\n",
    "for (label, count) in Counter(train_data['label']).items():\n",
    "    label_prob[label]=count/len(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae085f09-ae98-43eb-bd5f-619ec4378bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5, 1: 0.5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416339d-9e52-4149-86d9-dd5eb33b03f3",
   "metadata": {},
   "source": [
    "### 5. **Feature Likelihoods (Word Probabilities)**\n",
    "\n",
    "The likelihood $P(x_i | C)$ represents the probability of observing the word $x_i$ in class $C$. This is calculated by counting how often the word $x_i$ appears in documents of class $C$, and then dividing by the total number of words in class $C$.\n",
    "\n",
    "To avoid the issue of zero probabilities (when a word doesn't appear in the training data for a given class), we use **Laplace smoothing**, which ensures that every word has a non-zero probability. The smoothed probability of a word $x_i$ given class $C$ is:\n",
    "\n",
    "$$\n",
    "P(x_i | C) = \\frac{count(x_i, C) + 1}{|V| + count(C)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $count(x_i, C)$ is the count of how many times the word $x_i$ appears in documents of class $C$.\n",
    "- $|V|$ is the size of the vocabulary (the number of distinct words).\n",
    "- $count(C)$ is the total number of words in class $C$.\n",
    "\n",
    "This is the probability of a word $x_i$ occurring in class $C$ after smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "889662af-f5ba-4c3e-82e3-80eff9fd8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_prob=defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "for text,label in zip(train_text,train_label ):\n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    for (idx, count) in Counter(tokens).items():\n",
    "        word_prob[label][idx]+=count\n",
    "\n",
    "for label in np.unique(train_label):\n",
    "    total_count=np.sum(list(word_prob[label].values()))\n",
    "    for idx in word_prob[label]:\n",
    "        word_prob[label][idx]=(word_prob[label][idx]+1)/(total_count+len(tokenizer.w2i))   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f2b19-39fd-4a00-9348-c66a48c65cb8",
   "metadata": {},
   "source": [
    "### 6. **Prediction**\n",
    "\n",
    "To classify a new document, we compute the posterior probability $P(C|X)$ for each class and choose the class with the highest posterior probability:\n",
    "\n",
    "$$\n",
    "\\hat{C} = \\arg\\max_{C} P(C) \\cdot \\prod_{i=1}^{n} P(x_i | C)\n",
    "$$\n",
    "\n",
    "This means we calculate the posterior probabilities for each class and select the class with the highest value. The class with the highest score is the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e26fd686-cd20-444f-a692-be0229bbe212",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=test_text[0]\n",
    "tokens=tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9680d2cf-6f27-464b-90b5-cf03bdb0fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_prob={}\n",
    "for label in np.unique(train_label):\n",
    "    prob=np.log(label_prob[label])\n",
    "    for token in tokens:\n",
    "        if token in tokenizer.i2w:\n",
    "            if word_prob[label][token]>0:\n",
    "             prob+=np.log(word_prob[label][token])\n",
    "            else:\n",
    "             prob+=np.log(1/len(tokenizer.w2i))\n",
    "        else:\n",
    "            prob+=np.log(1/len(tokenizer.w2i))\n",
    "    sent_prob[label]=prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3929e28-28ca-4423-b689-f17d4e23b2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.424001058228837"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(word_prob[label][token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b230164-ab43-424f-b767-f481a9d92093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(list(sent_prob.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4246c68-fe43-4165-acc2-96470954ae16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92a533ca-d6fa-4eb2-9cc3-aa513f0784c0",
   "metadata": {},
   "source": [
    "### 7. **Final Formula for Naive Bayes Classification**\n",
    "\n",
    "Putting everything together, the Naive Bayes classifier predicts the class $C$ for a document $X = (x_1, x_2, ..., x_n)$ by maximizing the following expression:\n",
    "\n",
    "$$\n",
    "\\hat{C} = \\arg\\max_{C} \\left( P(C) \\cdot \\prod_{i=1}^{n} P(x_i | C) \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $P(C)$ is the class prior.\n",
    "- $P(x_i | C)$ is the likelihood of the word $x_i$ given the class $C$, smoothed using Laplace smoothing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "111b9667-3ec7-4135-b046-ec85c7f55e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "for text in test_text: \n",
    "    tokens=tokenizer.tokenize(text)\n",
    "    sent_prob={}\n",
    "    for label in np.unique(train_label):\n",
    "        prob=np.log(label_prob[label])\n",
    "        for token in tokens:\n",
    "            if token in tokenizer.i2w:\n",
    "                if word_prob[label][token]>0:\n",
    "                 prob+=np.log(word_prob[label][token])\n",
    "                else:\n",
    "                 prob+=np.log(1/len(tokenizer.w2i))\n",
    "            else:\n",
    "                prob+=np.log(1/len(tokenizer.w2i))\n",
    "        sent_prob[label]=prob\n",
    "    predictions.append(np.argmax(list(sent_prob.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d1f89-fb93-4e2d-9ab9-55b1f12671d2",
   "metadata": {},
   "source": [
    "### 9. **Evaluation**\n",
    "\n",
    "To evaluate the performance of the Naive Bayes classifier, we use metrics such as **accuracy**, **precision**, **recall**, and **F1-score**:\n",
    "\n",
    "- **Accuracy**: Measures the overall correctness of the model.\n",
    "- **Precision**: The proportion of positive predictions that were actually positive.\n",
    "- **Recall**: The proportion of actual positives that were correctly predicted.\n",
    "- **F1-score**: The harmonic mean of precision and recall, balancing both.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e61f6fc1-a389-4d55-9668-104f02fac12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.834\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy :', np.mean(np.array(predictions)==np.array(test_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e570446-d220-4dbc-ac51-9c45a84ea15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cb06b5e-de3a-4d27-995a-65f1d04ef82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true= np.array(predictions), np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62286e14-e5c1-4c49-91a4-f7db9175743d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_true), 1-np.mean(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ef3a2da-5b4e-4eec-bd75-c23a3a9bd933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5\n",
      "1 0.5\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for key, count in Counter(y_true).items():\n",
    "    print(key, count/len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "335520ce-1c6a-43e6-aeb0-395f3a1056ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10937,  1563],\n",
       "       [ 2587,  9913]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29cbe0d3-b2fe-4cea-9046-6f110cdf95aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Neg       0.81      0.87      0.84     12500\n",
      "         Pos       0.86      0.79      0.83     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.84      0.83      0.83     25000\n",
      "weighted avg       0.84      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['Neg', 'Pos']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f5d002-f00c-43a6-9c3e-04002da4622c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
