{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d45a0d5-184c-407d-ad89-1cd25c767392",
   "metadata": {},
   "source": [
    "## Training a Multi-Layer Perceptron (MLP) with Random Data\n",
    "\n",
    "### Introduction\n",
    "In this notebook, we will use a randomly generated dataset to train a Multi-Layer Perceptron (MLP) using PyTorch. This will help us understand the workflow of training a neural network, without relying on pre-existing datasets like MNIST.\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "We will generate random data $ \\mathbf{X} \\in \\mathbb{R}^{N \\times D} $ (where $N$ is the number of samples and $D$ is the number of features) and corresponding labels $\\mathbf{y} \\in \\mathbb{R}^{N} $, where the target is a random binary label (0 or 1).\n",
    "\n",
    "The neural network will have:\n",
    "1. An input layer with $D$ input features.\n",
    "2. Two hidden layers with ReLU activations.\n",
    "3. An output layer producing a probability (output between 0 and 1) using the sigmoid function.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Install PyTorch and Dependencies\n",
    "\n",
    "```python\n",
    "# First, let's install PyTorch (if not already installed)\n",
    "!pip install torch \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef7bc0-f832-41dd-825b-763cbc1b8df1",
   "metadata": {},
   "source": [
    "### 2. Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e8e8c-2094-4930-9c9a-b667fa1c400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993d974-23b9-42d8-a5ea-014b98c3f482",
   "metadata": {},
   "source": [
    "### 3. Generate Random Data\n",
    "\n",
    "Here, we will generate synthetic data with $N = 1000$ samples and $D = 20$ features. The labels will be binary (0 or 1) and randomly assigned.\n",
    "\n",
    "- $X$ is a tensor of size $N \\times D$, where each row represents an input sample with $D$ features.\n",
    "- $y$ is a tensor of size $N$, where each value is either 0 or 1, representing the label for each sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f4576-694d-4915-9b1b-99277a7e8722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data (N samples, D features)\n",
    "N = 1000  # Number of samples\n",
    "D = 20    # Number of features\n",
    "\n",
    "# Random input data (features)\n",
    "X = torch.randn(N, D)\n",
    "\n",
    "# Random binary labels (target output)\n",
    "y = torch.randint(0, 2, (N,))  # Random binary labels (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b1ed0d-770b-428a-9380-74c291f8cde8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39f9f047-e9d6-4829-a2e5-6923b00a8dc1",
   "metadata": {},
   "source": [
    "\n",
    "### 4. Define the MLP Model\n",
    "\n",
    "We will define a simple MLP with:\n",
    "1. An input layer of size $D$,\n",
    "2. Two hidden layers (with 64 and 32 neurons respectively),\n",
    "3. An output layer with 1 neuron, applying a sigmoid activation to output a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b846ca-592a-4f4e-82f8-03aa1002225c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f41ffd7-432b-4e04-a0ec-70e35f4e33ba",
   "metadata": {},
   "source": [
    "### 5. Define Loss and Optimizer\n",
    "\n",
    "For this binary classification task, we will use **Binary Cross-Entropy Loss** and the **Stochastic Gradient Descent (SGD)** optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad68dec-6eb5-4cf3-bffb-41b419d0082e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b515af9-afb5-47e3-b5dc-6f730a958047",
   "metadata": {},
   "source": [
    "### 6. Split the Data into Training and Validation Sets\n",
    "\n",
    "We will randomly split the data into 80% for training and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435657ae-0996-4acd-a2ab-084ff4bbbdec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d33c7e2a-b045-44e6-b628-ee7e6b5828dd",
   "metadata": {},
   "source": [
    "### 7. Train the Model\n",
    "\n",
    "Now, we will define the training loop and train the model for several epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec9d3c-7136-4129-9cc4-0f5eeefbb0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c28e712-0fea-45ff-89cc-f1a509c8861a",
   "metadata": {},
   "source": [
    "### 8. Evaluate the Model\n",
    "\n",
    "After training, we will evaluate the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66766d-33be-4816-ad82-8b38fc92ccd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bfe65a6-5ffa-4517-962b-eba059c5c13a",
   "metadata": {},
   "source": [
    "### 9. Visualize Some Predictions\n",
    "\n",
    "Finally, let's visualize some of the predictions made by the model on the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9edb7a-b92d-4954-8252-3c44dcc4f06f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
