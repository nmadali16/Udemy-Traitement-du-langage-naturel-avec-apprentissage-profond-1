{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#pip uninstall torchtext"
      ],
      "metadata": {
        "id": "dotFoO1dqzK8"
      },
      "id": "dotFoO1dqzK8",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install torchtext==0.15.1"
      ],
      "metadata": {
        "id": "eCV90Mynqm2j"
      },
      "id": "eCV90Mynqm2j",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install datasets"
      ],
      "metadata": {
        "id": "bOMVhfOMr2Tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2078633-90af-40c6-c5f7-d3eb936815c1"
      },
      "id": "bOMVhfOMr2Tb",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f23a152d",
      "metadata": {
        "id": "f23a152d"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "from torchtext.data import get_tokenizer\n",
        "import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchtext\n",
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c661e3c4",
      "metadata": {
        "id": "c661e3c4"
      },
      "outputs": [],
      "source": [
        "seed = 1234\n",
        "\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "638a120e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "638a120e",
        "outputId": "497121af-a50f-4b53-deaa-fabf44dea937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_data, test_data = datasets.load_dataset(\"imdb\", split=[\"train\", \"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "13358bff-80e2-41ff-9979-fb53311934f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13358bff-80e2-41ff-9979-fb53311934f7",
        "outputId": "e91f64de-a4c2-4872-df11-10f75a4dcb8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 25000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7b34799a",
      "metadata": {
        "id": "7b34799a"
      },
      "outputs": [],
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6fa2f2e3",
      "metadata": {
        "id": "6fa2f2e3"
      },
      "outputs": [],
      "source": [
        "def tokenize_example(example, tokenizer, max_length):\n",
        "    tokens = ['<bos>']+tokenizer(example[\"text\"])[:max_length-2]+['<eos>']\n",
        "    length = len(tokens)\n",
        "    return {\"tokens\": tokens, \"length\": length}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "1f3a3894",
      "metadata": {
        "id": "1f3a3894"
      },
      "outputs": [],
      "source": [
        "max_length = 256\n",
        "\n",
        "train_data = train_data.map(\n",
        "    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",
        ")\n",
        "test_data = test_data.map(\n",
        "    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7e5bd85d",
      "metadata": {
        "id": "7e5bd85d"
      },
      "outputs": [],
      "source": [
        "test_size = 0.25\n",
        "\n",
        "train_valid_data = train_data.train_test_split(test_size=test_size)\n",
        "train_data = train_valid_data[\"train\"]\n",
        "valid_data = train_valid_data[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0bf984df",
      "metadata": {
        "id": "0bf984df"
      },
      "outputs": [],
      "source": [
        "min_freq = 5\n",
        "special_tokens = [\"<unk>\", \"<pad>\"]\n",
        "\n",
        "vocab =  torchtext.vocab.build_vocab_from_iterator(\n",
        "    train_data[\"tokens\"],\n",
        "    min_freq=min_freq,\n",
        "    specials=special_tokens,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "5147a8fd",
      "metadata": {
        "id": "5147a8fd"
      },
      "outputs": [],
      "source": [
        "unk_index = vocab[\"<unk>\"]\n",
        "pad_index = vocab[\"<pad>\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8b97bda7",
      "metadata": {
        "id": "8b97bda7"
      },
      "outputs": [],
      "source": [
        "vocab.set_default_index(unk_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "843282aa",
      "metadata": {
        "id": "843282aa"
      },
      "outputs": [],
      "source": [
        "def numericalize_example(example, vocab):\n",
        "    ids = vocab.lookup_indices(example[\"tokens\"])\n",
        "    return {\"ids\": ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "885b504a",
      "metadata": {
        "id": "885b504a"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
        "valid_data = valid_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n",
        "test_data = test_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "2b956558",
      "metadata": {
        "id": "2b956558"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n",
        "valid_data = valid_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n",
        "test_data = test_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "53575424",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53575424",
        "outputId": "f7f2a1e7-ed46-4018-9729-90149a3599f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': tensor(1),\n",
              " 'length': tensor(137),\n",
              " 'ids': tensor([   26,   182,     4,    14,    10,   193,   840,    36,     7,     2,\n",
              "           123,   100,   818,    52,     8,  1528,     2,   382,     7,     2,\n",
              "           187,     3,     8,   806,    14,    18,    10,     8,   806,  2257,\n",
              "           431,     3,    12,   349,    15,     2,   390,  1022,     9,    16,\n",
              "            78,     5,    66,     7, 11170,     3,     2,  9198,    17,   762,\n",
              "             4,  7791,  5447,   200,    39,     4,     6,  3651,  3679,    17,\n",
              "           229,     5, 11865,     3,    55,     7,    15,  3298,   356,     5,\n",
              "           688,     4,     0,  5457,     3,  2726,  3815,     9,    16,   248,\n",
              "            13,    14,    18,  1111,    35,    17,   129,   190,     8,    37,\n",
              "           599,   183,    19,     5,    36,  3934,  1388,    13,     2,  5361,\n",
              "             3,    34,  4214,    10,    43,  2815,     8,    39,     3,     2,\n",
              "          4475,  1148,   215,  2646,     6, 16912,  3719,   591,  4827,     8,\n",
              "          2415,     6,  1945,     3,  1160, 20723,    10,     5,  8981,     3,\n",
              "           151,    76,    14,    18,  4281,    38,    27])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3a5e5883",
      "metadata": {
        "id": "3a5e5883"
      },
      "outputs": [],
      "source": [
        "def get_collate_fn(pad_index):\n",
        "    def collate_fn(batch):\n",
        "        batch_ids = [i[\"ids\"] for i in batch]\n",
        "        batch_ids = nn.utils.rnn.pad_sequence(\n",
        "            batch_ids, padding_value=pad_index, batch_first=True\n",
        "        )\n",
        "        batch_length = [i[\"length\"] for i in batch]\n",
        "        batch_length = torch.stack(batch_length)\n",
        "        batch_label = [i[\"label\"] for i in batch]\n",
        "        batch_label = torch.stack(batch_label)\n",
        "        batch = {\"ids\": batch_ids, \"length\": batch_length, \"label\": batch_label}\n",
        "        return batch\n",
        "\n",
        "    return collate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6a2bb50a",
      "metadata": {
        "id": "6a2bb50a"
      },
      "outputs": [],
      "source": [
        "def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n",
        "    collate_fn = get_collate_fn(pad_index)\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        collate_fn=collate_fn,\n",
        "        shuffle=shuffle,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "2d8f0a73",
      "metadata": {
        "id": "2d8f0a73"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\n",
        "valid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\n",
        "test_data_loader = get_data_loader(test_data, batch_size, pad_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fun2(data, input_lens):\n",
        "    N, C, H =data.shape\n",
        "    device=data.get_device()\n",
        "\n",
        "    idx = torch.arange(C).unsqueeze(0).expand(N, -1)\n",
        "    idx = idx < input_lens.unsqueeze(1)\n",
        "    idx = idx.unsqueeze(2).expand(-1, -1, H).to(device)\n",
        "\n",
        "    ret = (data * idx.float()).sum(1) / input_lens.unsqueeze(1).float().to(device)\n",
        "    return ret\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        embedding_dim,\n",
        "        hidden_dim,\n",
        "        n_layers,\n",
        "        dropout_rate,\n",
        "        pad_index,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim,\n",
        "            hidden_dim,\n",
        "            n_layers,\n",
        "            bidirectional=False,\n",
        "            dropout=dropout_rate,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim,vocab_size,bias=True)  #nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, ids):\n",
        "        # ids = [batch size, seq len]\n",
        "        # length = [batch size]\n",
        "        embedded = self.dropout(self.embedding(ids))\n",
        "\n",
        "        output, _ = self.lstm(embedded)\n",
        "\n",
        "        output = self.fc(output)\n",
        "        return output\n",
        "    def sentence_embedding(self,ids, lengths):\n",
        "\n",
        "      embedded = self.dropout(self.embedding(ids))\n",
        "\n",
        "      output, _ = self.lstm(embedded) #B, seq_len, hidden_dim\n",
        "      ret = torch.stack([\n",
        "        torch.sum(output[i, :l, :], dim=0) / l for i, l in enumerate(lengths)\n",
        "       ])\n",
        "      return ret"
      ],
      "metadata": {
        "id": "81IEHq2YJidI"
      },
      "id": "81IEHq2YJidI",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "53427b55",
      "metadata": {
        "id": "53427b55"
      },
      "outputs": [],
      "source": [
        "class CLASSIFIER(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size,\n",
        "        embedding_dim,\n",
        "        hidden_dim,\n",
        "        output_dim,\n",
        "        n_layers,\n",
        "        dropout_rate,\n",
        "        pad_index,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.text_encoder=LSTM(vocab_size,\n",
        "                embedding_dim,\n",
        "                hidden_dim,\n",
        "                n_layers,\n",
        "                dropout_rate,\n",
        "                pad_index,)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim , output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, ids, lengths):\n",
        "        with torch.no_grad():\n",
        "          hidden=self.text_encoder.sentence_embedding(ids, lengths).detach()\n",
        "        prediction = self.fc(hidden)\n",
        "\n",
        "        return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "11206188",
      "metadata": {
        "id": "11206188",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c6f9fd1-ee66-43a2-8081-899fc2e3070d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "hidden_dim = 256\n",
        "output_dim = len(train_data.unique(\"label\"))\n",
        "n_layers = 1\n",
        "dropout_rate = 0.25\n",
        "\n",
        "model = CLASSIFIER(\n",
        "    vocab_size,\n",
        "    embedding_dim,\n",
        "    hidden_dim,\n",
        "    output_dim,\n",
        "    n_layers,\n",
        "    dropout_rate,\n",
        "    pad_index,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5feb9512",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5feb9512",
        "outputId": "616897e6-97d4-4314-c9e9-116f88c0f7d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 11,611,241 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e2d0b14e",
      "metadata": {
        "id": "e2d0b14e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "053ffa58-c2d4-4b6e-fc69-2f34a9701664"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1xrvosUfmglb01gnMWOSXYwvdecYwtxB0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shw5ko0gc_Ag",
        "outputId": "292f3582-4c64-4640-f362-dd16dbeca0b7"
      },
      "id": "Shw5ko0gc_Ag",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1xrvosUfmglb01gnMWOSXYwvdecYwtxB0\n",
            "From (redirected): https://drive.google.com/uc?id=1xrvosUfmglb01gnMWOSXYwvdecYwtxB0&confirm=t&uuid=59e3afac-4627-43ec-b9fc-ce8ea7c27d89\n",
            "To: /content/pretrained_lstm.pth\n",
            "  0% 0.00/46.4M [00:00<?, ?B/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.isfile(\"pretrained_lstm.pth\"):\n",
        "  print('Loading a Pretrained Language Model')\n",
        "  model.text_encoder.load_state_dict(torch.load(\"pretrained_lstm.pth\", weights_only=True))"
      ],
      "metadata": {
        "id": "Es3eBu4WYK8C"
      },
      "id": "Es3eBu4WYK8C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c8302f0",
      "metadata": {
        "id": "5c8302f0"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a1e9b07",
      "metadata": {
        "id": "8a1e9b07"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    epoch_losses = []\n",
        "    epoch_accs = []\n",
        "    for batch in tqdm.tqdm(dataloader, desc=\"training...\"):\n",
        "        ids = batch[\"ids\"].to(device)\n",
        "        length = batch[\"length\"]\n",
        "        label = batch[\"label\"].to(device)\n",
        "        prediction = model(ids, length)\n",
        "        loss = criterion(prediction, label)\n",
        "        accuracy = get_accuracy(prediction, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_losses.append(loss.item())\n",
        "        epoch_accs.append(accuracy.item())\n",
        "    return np.mean(epoch_losses), np.mean(epoch_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7988786",
      "metadata": {
        "id": "c7988786"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader, model, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_losses = []\n",
        "    epoch_accs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(dataloader, desc=\"evaluating...\"):\n",
        "            ids = batch[\"ids\"].to(device)\n",
        "            length = batch[\"length\"]\n",
        "            label = batch[\"label\"].to(device)\n",
        "            prediction = model(ids, length)\n",
        "            loss = criterion(prediction, label)\n",
        "            accuracy = get_accuracy(prediction, label)\n",
        "            epoch_losses.append(loss.item())\n",
        "            epoch_accs.append(accuracy.item())\n",
        "    return np.mean(epoch_losses), np.mean(epoch_accs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d66535bd",
      "metadata": {
        "id": "d66535bd"
      },
      "outputs": [],
      "source": [
        "def get_accuracy(prediction, label):\n",
        "    batch_size, _ = prediction.shape\n",
        "    predicted_classes = prediction.argmax(dim=-1)\n",
        "    correct_predictions = predicted_classes.eq(label).sum()\n",
        "    accuracy = correct_predictions / batch_size\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24c05b57",
      "metadata": {
        "id": "24c05b57"
      },
      "outputs": [],
      "source": [
        "n_epochs = 20\n",
        "best_valid_loss = float(\"inf\")\n",
        "\n",
        "metrics = collections.defaultdict(list)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss, train_acc = train(\n",
        "        train_data_loader, model, criterion, optimizer, device\n",
        "    )\n",
        "    valid_loss, valid_acc = evaluate(valid_data_loader, model, criterion, device)\n",
        "    metrics[\"train_losses\"].append(train_loss)\n",
        "    metrics[\"train_accs\"].append(train_acc)\n",
        "    metrics[\"valid_losses\"].append(valid_loss)\n",
        "    metrics[\"valid_accs\"].append(valid_acc)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), \"lstm.pt\")\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    print(f\"train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}\")\n",
        "    print(f\"valid_loss: {valid_loss:.3f}, valid_acc: {valid_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b360d0cd",
      "metadata": {
        "id": "b360d0cd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(metrics[\"train_losses\"], label=\"train loss\")\n",
        "ax.plot(metrics[\"valid_losses\"], label=\"valid loss\")\n",
        "ax.set_xlabel(\"epoch\")\n",
        "ax.set_ylabel(\"loss\")\n",
        "ax.set_xticks(range(n_epochs))\n",
        "ax.legend()\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742a6855",
      "metadata": {
        "id": "742a6855"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 6))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(metrics[\"train_accs\"], label=\"train accuracy\")\n",
        "ax.plot(metrics[\"valid_accs\"], label=\"valid accuracy\")\n",
        "ax.set_xlabel(\"epoch\")\n",
        "ax.set_ylabel(\"loss\")\n",
        "ax.set_xticks(range(n_epochs))\n",
        "ax.legend()\n",
        "ax.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b89f53f",
      "metadata": {
        "id": "8b89f53f"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(\"lstm.pt\"))\n",
        "\n",
        "test_loss, test_acc = evaluate(test_data_loader, model, criterion, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10bc7bc3",
      "metadata": {
        "id": "10bc7bc3"
      },
      "outputs": [],
      "source": [
        "print(f\"test_loss: {test_loss:.3f}, test_acc: {test_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07df383",
      "metadata": {
        "id": "c07df383"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text, model, tokenizer, vocab, device):\n",
        "    tokens = tokenizer(text)\n",
        "    ids = vocab.lookup_indices(tokens)\n",
        "    length = torch.LongTensor([len(ids)])\n",
        "    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n",
        "    prediction = model(tensor, length).squeeze(dim=0)\n",
        "    probability = torch.softmax(prediction, dim=-1)\n",
        "    predicted_class = prediction.argmax(dim=-1).item()\n",
        "    predicted_probability = probability[predicted_class].item()\n",
        "    return predicted_class, predicted_probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d9d591d",
      "metadata": {
        "id": "8d9d591d"
      },
      "outputs": [],
      "source": [
        "text = \"This film is terrible!\"\n",
        "\n",
        "predict_sentiment(text, model, tokenizer, vocab, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f392b05a",
      "metadata": {
        "id": "f392b05a"
      },
      "outputs": [],
      "source": [
        "text = \"This film is great!\"\n",
        "\n",
        "predict_sentiment(text, model, tokenizer, vocab, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3196951d",
      "metadata": {
        "id": "3196951d"
      },
      "outputs": [],
      "source": [
        "text = \"a bad movie\"\n",
        "\n",
        "predict_sentiment(text, model, tokenizer, vocab, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35aeb03",
      "metadata": {
        "id": "c35aeb03"
      },
      "outputs": [],
      "source": [
        "text = \"just amazing\"\n",
        "\n",
        "predict_sentiment(text, model, tokenizer, vocab, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b6cb78-4613-4e3c-a845-342f1a2de63f",
      "metadata": {
        "id": "09b6cb78-4613-4e3c-a845-342f1a2de63f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "449c3d7c-d185-4a01-adc3-2ba5350ff82b",
      "metadata": {
        "id": "449c3d7c-d185-4a01-adc3-2ba5350ff82b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a25489-aaf3-4adf-87ff-d21109ed4420",
      "metadata": {
        "id": "81a25489-aaf3-4adf-87ff-d21109ed4420"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}