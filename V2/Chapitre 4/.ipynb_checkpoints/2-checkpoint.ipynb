{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "780c3d93-1ed1-4aa6-b67f-1484948eb039",
   "metadata": {},
   "source": [
    "# Evaluating Word Embeddings Using WordSim-353\n",
    "\n",
    "In this lab, you will learn how to evaluate word embeddings using the WordSim-353 dataset. \n",
    "\n",
    "Word embeddings are a way to represent words as vectors in a continuous vector space. Evaluating these embeddings is essential to understand their effectiveness in capturing semantic and syntactic relationships.\n",
    "\n",
    "The WordSim-353 dataset is a standard benchmark used for this purpose. It contains 353 pairs of English words along with human-assigned similarity scores. The task is to calculate the similarity scores using word embeddings and compare them to human judgments using correlation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd12cf-c90a-46fd-992a-34fd9efdfc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f91a6d5-d240-4ad1-84f7-deefa86d4914",
   "metadata": {},
   "source": [
    "### Step 1: Load the WordSim-353 Dataset\n",
    "\n",
    "The WordSim-353 dataset is publicly available. You can download it from the internet or use the version included in this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc184202-4e64-451c-9622-b1b75e00a9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a62fa91-69bd-41a5-a62d-7a64f68ad622",
   "metadata": {},
   "source": [
    "### Step 2: Load Pre-trained Word Embeddings\n",
    "\n",
    "Word embeddings like GloVe or Word2Vec are commonly used for these evaluations. We will use the GloVe embeddings in this lab. \n",
    "\n",
    "Download pre-trained embeddings (if not already downloaded):\n",
    " ```bash\n",
    " wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    " unzip glove.6B.zip\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d285c12-399c-4942-8cc0-67ebe3846171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b45d334e-f921-47b0-9c04-5918d52eac31",
   "metadata": {},
   "source": [
    "#### Load the embeddings using Gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a77257-9d47-471a-a3f3-2e9b2ddae3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "429aa78c-1c7c-4250-ac7c-ba68cb22e4fa",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ea546-a23f-4eb1-8878-c2bd839f1dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3922b18d-65d1-44b8-8351-bde8395e8c41",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate Using Spearman Correlation\n",
    "\n",
    "The **Spearman correlation coefficient** (denoted as $ \\rho$ or $ r_s$) measures the strength and direction of a monotonic relationship between two variables. Unlike the Pearson correlation, Spearman's does not assume a linear relationship or normal distribution of the variables. Instead, it evaluates how well the relationship between two variables can be described using a monotonic function.\n",
    "\n",
    "Spearman correlation is calculated by first converting the data values into ranks, then applying the Pearson correlation formula to the ranked data. It is especially useful for ordinal data or when the relationship between variables is not linear.\n",
    "\n",
    "### Formula\n",
    "\n",
    "The Spearman correlation coefficient is given by:\n",
    "\n",
    "$$\n",
    "\\rho = 1 - \\frac{6 \\sum d_i^2}{n(n^2 - 1)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ d_i = R(x_i) - R(y_i)$: The difference between the ranks of corresponding values of $ x$ and $ y$.\n",
    "- $ R(x_i)$ and $ R(y_i)$: The ranks of the $ i$-th observation in $ x$ and $ y$, respectively.\n",
    "- $ n$: The number of data points.\n",
    "\n",
    "### Steps to Calculate Spearman Correlation\n",
    "\n",
    "1. Assign ranks to the data values for each variable.\n",
    "2. Compute the rank differences ($ d_i$).\n",
    "3. Square the rank differences and sum them ($ \\sum d_i^2$).\n",
    "4. Apply the formula to find $ \\rho$.\n",
    "\n",
    "The Spearman correlation ranges from $-1\\) to $1\\):\n",
    "- $ \\rho = 1$: Perfect positive monotonic relationship.\n",
    "- $ \\rho = -1$: Perfect negative monotonic relationship.\n",
    "- $ \\rho = 0$: No monotonic relationship.\n",
    "\n",
    "### Example\n",
    "\n",
    "If we have the data:\n",
    "\n",
    "| $ x$ | $ y$ |\n",
    "|--------|--------|\n",
    "| 10     | 20     |\n",
    "| 20     | 30     |\n",
    "| 30     | 10     |\n",
    "\n",
    "We would rank the values of $ x$ and $ y$, calculate $ d_i$, and apply the formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713cf7a-cec6-40ae-837f-18873ac27536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c4a7dc3-80dc-424c-a023-f9690990a119",
   "metadata": {},
   "source": [
    "### Step 5: Interpret Results\n",
    "\n",
    "A higher Spearman correlation indicates that the word embeddings better capture the semantic relationships as perceived by humans. Typical results for good embeddings range from 0.6 to 0.8, depending on the dataset and model.\n",
    "\n",
    "#wv_glove_200.evaluate_word_pairs(datapath('wordsim353.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9619e4d-ad55-42e8-b822-3c1bc05e2bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba0da3e3-1cfc-4534-806d-84798861ef34",
   "metadata": {},
   "source": [
    "### Part 2: Evaluating GloVe with Analogies\n",
    "\n",
    "Word embeddings are often evaluated using analogy tasks. In these tasks, we assess whether embeddings can correctly complete analogies such as \"man : king :: woman : ?\" (answer: \"queen\").\n",
    "\n",
    "### Step 1: Load the Analogy Dataset\n",
    "\n",
    "Analogies are often organized in text files with four words per line: word1, word2, word3, and word4. \n",
    "The goal is to predict word4, given word1, word2, and word3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68405cf-326e-459d-9491-c8a4477d8731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6c0eeb-cfa1-4c97-beb0-6c78838f2115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Code\n",
    "analogy_data_url = \"https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt\"\n",
    "analogy_lines = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517904a-b6ea-49fc-b935-c6e256fd237b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f17d17-f818-4a7e-b12f-8edbc319f880",
   "metadata": {},
   "source": [
    "### Step 3: Solve Analogies Using GloVe\n",
    "\n",
    "To solve analogies, we use the vector arithmetic property of embeddings:\n",
    "$$vec(word2) - vec(word1) + vec(word3) â‰ˆ vec(word4)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe18ef0-f45e-4fe9-83af-be9d0e6602a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wv_glove_200.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aac8e0-ae81-4760-b3ac-d3d6db841df6",
   "metadata": {},
   "source": [
    "### Step 3: Interpret Results\n",
    "\n",
    "The analogy accuracy gives us insight into how well the embeddings capture relational semantics. Common analogies include relationships like gender (man:king::woman:queen) and geography (Paris:France::Berlin:Germany)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4dfac6-9d18-486c-bdc5-2c8f3f1f6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.test.utils import datapath\n",
    "#wv_glove_200.evaluate_word_analogies(datapath('questions-words.txt'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
