{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4e805a2-1d3c-473c-bf0a-cbd8ca4f6899",
   "metadata": {},
   "source": [
    "# Introduction to TF-IDF\n",
    "\n",
    "In this notebook, we will compute the **Term Frequency-Inverse Document Frequency (TF-IDF)** of a set of text documents. TF-IDF is a numerical statistic that reflects the importance of a word within a document, relative to a collection of documents (corpus).\n",
    "\n",
    "- **Term Frequency (TF)**: Measures how frequently a term (word) appears in a document.\n",
    "- **Inverse Document Frequency (IDF)**: Measures how important a term is in the whole corpus. It gives less weight to terms that appear frequently across all documents.\n",
    "\n",
    "We will first compute TF-IDF manually, and then use the `TfidfVectorizer` from `scikit-learn` to compute it more efficiently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b502e8ec-5eee-49d5-9a84-f2eb1ecee68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1fc08e-2541-4007-a14b-97d237c06d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_str = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"A dog sat on the mat.\",\n",
    "    \"The bird flew over the tree.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b9a62c-10bd-43b7-b20f-112169c536ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1831020481113516"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1/6)*np.log(3/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c87e120c-5448-4482-bdf6-b2a5f2ff57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    return sent.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c5c8058-c592-45db-979a-4e58c49dadd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sat on the mat. ['the', 'cat', 'sat', 'on', 'the', 'mat.']\n",
      "A dog sat on the mat. ['a', 'dog', 'sat', 'on', 'the', 'mat.']\n",
      "The bird flew over the tree. ['the', 'bird', 'flew', 'over', 'the', 'tree.']\n"
     ]
    }
   ],
   "source": [
    "vocab={}\n",
    "for doc in documents_str:\n",
    "    tokens=tokenize(doc)\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "            vocab[token]+=1\n",
    "        else: \n",
    "            vocab[token]=1\n",
    "    print(doc, tokenize(doc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2faef26-b56e-4434-b936-1c3463300f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 5, 'cat': 1, 'sat': 2, 'on': 2, 'mat.': 2, 'a': 1, 'dog': 1, 'bird': 1, 'flew': 1, 'over': 1, 'tree.': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c292241f-21e4-4345-b43c-64b5d0e3b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2token={ k:idx for idx,(k,v) in enumerate(vocab.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126e0a77-5a4a-4ccf-b8aa-6e024231e872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'cat': 1,\n",
       " 'sat': 2,\n",
       " 'on': 3,\n",
       " 'mat.': 4,\n",
       " 'a': 5,\n",
       " 'dog': 6,\n",
       " 'bird': 7,\n",
       " 'flew': 8,\n",
       " 'over': 9,\n",
       " 'tree.': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "228e546f-722f-4cd8-a009-d57749931b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2word={ v:k for (k,v) in word2token.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876dddb8-3c28-48d0-9b30-3c78abf32651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'the',\n",
       " 1: 'cat',\n",
       " 2: 'sat',\n",
       " 3: 'on',\n",
       " 4: 'mat.',\n",
       " 5: 'a',\n",
       " 6: 'dog',\n",
       " 7: 'bird',\n",
       " 8: 'flew',\n",
       " 9: 'over',\n",
       " 10: 'tree.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c9a5a-04c5-48b0-8ea2-b240fc18ebe6",
   "metadata": {},
   "source": [
    "### 1 Term Frequency (TF)\n",
    "\n",
    "TF measures the frequency of a word within a document. It is calculated as:\n",
    "\n",
    "$$\n",
    "TF(w, D) = \\frac{\\text{Number of times word } w \\text{ appears in document } D}{\\text{Total number of words in document } D}\n",
    "$$\n",
    "\n",
    "For example, in the document `['the', 'cat', 'sat', 'on', 'the', 'mat']`, the term frequency of \"the\" is$ \\frac{2}{6} = 0.333 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4962bda-061b-47a2-adb0-31fef873a5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cat', 'sat', 'on', 'the', 'mat.']\n"
     ]
    }
   ],
   "source": [
    "sent=documents_str[0]\n",
    "tokens=tokenize(sent)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b96e8e0-e2aa-4190-a0cc-f85c184d0704",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF=np.zeros(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02a1dd15-e605-49a1-9493-b6f201c320f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in tokens:\n",
    "    TF[word2token[token]]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6e0d5a9-6483-49b6-be52-dd3c26a0353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF/=len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c795fb8-d7b1-4027-8cba-373f94441205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33333333, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4561641f-7b15-4d9c-9d48-2093f09c24cc",
   "metadata": {},
   "source": [
    "\n",
    "### 2 Inverse Document Frequency (IDF)\n",
    "\n",
    "IDF measures the importance of a word in the whole corpus. The formula is:\n",
    "\n",
    "$$\n",
    "IDF(w) = \\log \\left( \\frac{1+N}{1+\\text{df}(w)} \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $N$ is the total number of documents.\n",
    "- $df(w)$ is the number of documents containing the word $w$.\n",
    "\n",
    "For example, the word \"the\" is very common across the corpus, so its IDF value would be low.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3187f00c-8081-42fe-b735-897e410e4a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=np.zeros(len(vocab))\n",
    "for doc in documents_str:\n",
    "    tokens=set(tokenize(doc))\n",
    "    for token in tokens:\n",
    "        DF[word2token[token]]+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e7c8a65-8599-4b8f-b0ee-63902f55e895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 1., 2., 2., 2., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b5490e6-fcd7-415a-bc9d-4c62b071247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF=np.zeros(len(vocab))\n",
    "for i in range(len(vocab)):\n",
    "    if DF[i]>0:\n",
    "        IDF[i]=np.log((1+len(documents_str))/(1+DF[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3aa490a6-1b61-45d2-b522-a8be1b9b805c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.69314718, 0.28768207, 0.28768207, 0.28768207,\n",
       "       0.69314718, 0.69314718, 0.69314718, 0.69314718, 0.69314718,\n",
       "       0.69314718])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ca23e-cc2f-43e5-82fe-431b6a1229a5",
   "metadata": {},
   "source": [
    "### 3 TF-IDF Computation\n",
    "\n",
    "The final TF-IDF value is obtained by multiplying the TF and IDF values for each word in a document. A high TF-IDF value means that the word is important in the document and less common across other documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd540ff-11c7-4df1-8163-0aef1dc9a0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.11552453 0.04794701 0.04794701 0.04794701 0.\n",
      " 0.         0.         0.         0.         0.        ]\n",
      "[0.         0.         0.04794701 0.04794701 0.04794701 0.11552453\n",
      " 0.11552453 0.         0.         0.         0.        ]\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.11552453 0.11552453 0.11552453 0.11552453]\n"
     ]
    }
   ],
   "source": [
    "TF_IDF=np.zeros((len(documents_str), len(vocab)))\n",
    "for idx_sent, sent in enumerate(documents_str):\n",
    "    tokens=tokenize(sent)\n",
    "    ###### TF (w,d) #\n",
    "    TF=np.zeros(len(vocab))\n",
    "    for token in tokens:\n",
    "        TF[word2token[token]]+=1\n",
    "    TF/=len(tokens)\n",
    "    \n",
    "    \n",
    "    for i in range(len(vocab)):\n",
    "        TF_IDF[idx_sent,i]=IDF[i]*TF[i]\n",
    "    print(TF_IDF[idx_sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac2f3de-ec8a-4dc9-ac6c-85d4074acbc0",
   "metadata": {},
   "source": [
    "### 4 Relationship Between TF-IDF and Stop Words\n",
    "\n",
    "1. **High Term Frequency (TF) but Low IDF**: Stop words tend to appear very frequently in documents, leading to a high term frequency. However, because they appear across almost every document in the corpus, their inverse document frequency (IDF) is low. This results in a low TF-IDF score for stop words, indicating their low relevance in distinguishing between documents.\n",
    "\n",
    "2. **Impact on TF-IDF Calculation**: Stop words don't help in distinguishing one document from another because they appear in nearly all documents. Hence, when calculating TF-IDF, the IDF component for stop words is very small, and their overall TF-IDF score becomes negligible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de131c0f-1498-49fe-9de5-4241e0f76b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2token[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8235f64a-ddca-4c00-b4c3-3ad7a7291e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDF[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f5fb2f-97dc-4828-a4b5-6144aa49e7de",
   "metadata": {},
   "source": [
    "### 5. How to Use TF-IDF to Compute Sentence Similarity\n",
    "To compute the similarity between two sentences, use **cosine similarity**, which measures the cosine of the angle between the two sentence vectors. The cosine similarity ranges from -1 (completely dissimilar) to 1 (identical). The formula for cosine similarity between two vectors $A$ and $B$ is:\n",
    "\n",
    "   $$\n",
    "   \\text{Cosine Similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
    "   $$\n",
    "   Where:\n",
    "   - $A \\cdot B$ is the dot product of vectors $A$ and $B$.\n",
    "   - $\\|A\\|$ and $\\|B\\|$ are the magnitudes (lengths) of the vectors.\n",
    "\n",
    "By applying TF-IDF and cosine similarity, we can compare sentences based on their content, taking into account the relative importance of each word. This method is particularly useful in tasks like **document clustering**, **information retrieval**, and **text classification**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20376263-6bda-4373-99e2-9f20a975150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "460d40af-75a0-470a-b9b3-0d0d22e92b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(A,B):\n",
    " return np.dot(A,B)/(norm(A)*norm(B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a9aff59-6e82-4fc2-8cb5-47568bd3e48a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'cat': 1,\n",
       " 'sat': 2,\n",
       " 'on': 3,\n",
       " 'mat.': 4,\n",
       " 'a': 5,\n",
       " 'dog': 6,\n",
       " 'bird': 7,\n",
       " 'flew': 8,\n",
       " 'over': 9,\n",
       " 'tree.': 10}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7961770-09e8-4aef-b31a-3a11605049ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.11552453, 0.04794701, 0.04794701, 0.04794701,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_IDF[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efcb071d-d0d0-4c7e-a8c9-18425eef8286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.11552453, 0.11552453, 0.11552453,\n",
       "       0.11552453])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TF_IDF[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ffbec23-b1eb-4ad7-81e7-295eb31057ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2644932986430687"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(TF_IDF[0],TF_IDF[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "378f7fc5-8887-4203-80fc-0b25fc790ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(TF_IDF[1],TF_IDF[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6394904e-0a22-4f03-be10-4a96cc7cb3b7",
   "metadata": {},
   "source": [
    "### 6. Using scikit-learn to Compute TF-IDF\n",
    "Now, let's use the TfidfVectorizer from the scikit-learn library to compute the TF-IDF values automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a84dfebd-0e2c-41d3-9871-496af41c5e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Sentence 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence 1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622028</td>\n",
       "      <td>0.227269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence 2</th>\n",
       "      <td>0.622028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence 3</th>\n",
       "      <td>0.227269</td>\n",
       "      <td>0.127796</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentence 1  Sentence 2  Sentence 3\n",
       "Sentence 1    1.000000    0.622028    0.227269\n",
       "Sentence 2    0.622028    1.000000    0.127796\n",
       "Sentence 3    0.227269    0.127796    1.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Sample sentences\n",
    "documents_str = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"A dog sat on the mat.\",\n",
    "    \"The bird flew over the tree.\"\n",
    "]\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(use_idf=True,smooth_idf=False, lowercase=True)\n",
    "\n",
    "# Fit and transform the documents to compute the TF-IDF matrix\n",
    "tfidf_matrix = vectorizer.fit_transform(documents_str)\n",
    "\n",
    "# Compute cosine similarity between all pairs of sentences\n",
    "cos_sim_matrix = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Show the cosine similarity matrix\n",
    "import pandas as pd\n",
    "cos_sim_df = pd.DataFrame(cos_sim_matrix, columns=[\"Sentence 1\", \"Sentence 2\", \"Sentence 3\"], \n",
    "                          index=[\"Sentence 1\", \"Sentence 2\", \"Sentence 3\"])\n",
    "cos_sim_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67feb15d-a686-4d56-91e3-5d4cec9914f6",
   "metadata": {},
   "source": [
    "*  The resultant idf (irrespective of the value of smooth_idf) is still combined  according to tf * (idf + 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e664821c-9bdf-4fbe-bf13-13f6e1245093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.idf_ [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "687e64a9-f354-4532-ba86-cf5c52788b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_[\"tree\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e49b3148-26fd-4d8e-9ac5-3bfdf06df534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bird', 'cat', 'dog', 'flew', 'mat', 'on', 'over', 'sat', 'the',\n",
       "       'tree'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63296bd-16bc-402b-9564-f20d3a9142ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
