{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes est un algorithme d'apprentissage automatique populaire utilisé pour les tâches de classification, en particulier dans le contexte de la classification de texte, comme la détection de spam. Il est basé sur le théorème de Bayes avec une hypothèse d'indépendance entre les caractéristiques. Malgré sa simplicité, Naive Bayes donne souvent de bons résultats et est efficace en termes de calcul.\n",
    "\n",
    "Voici un bref aperçu de la façon dont fonctionne Naive Bayes pour la classification de spam :\n",
    "\n",
    "1. **Compréhension du théorème de Bayes** :\n",
    "\n",
    "   Le théorème de Bayes calcule la probabilité d'un événement en fonction des probabilités d'autres événements. Dans le contexte de la classification, il est utilisé pour estimer la probabilité d'une certaine classe (dans ce cas, \"spam\" ou \"non spam\") étant donné les caractéristiques (mots ou attributs) d'une donnée.\n",
    "\n",
    "   La formule est :\n",
    "\n",
    "   $$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "   - $P(A|B)$ : Probabilité de la classe A sachant l'évidence B.\n",
    "   - $P(B|A)$ : Probabilité de l'évidence B sachant la classe A.\n",
    "   - $P(A)$ : Probabilité de la classe A.\n",
    "   - $P(B)$ : Probabilité de l'évidence B.\n",
    "\n",
    "2. **L'hypothèse naïve** :\n",
    "\n",
    "   La partie \"naïve\" de Naive Bayes vient de l'hypothèse d'indépendance des caractéristiques. Il suppose que la présence ou l'absence d'une caractéristique particulière est indépendante de la présence ou de l'absence de toute autre caractéristique. Cela n'est souvent pas vrai dans les données du monde réel, mais l'algorithme peut tout de même être étonnamment efficace.\n",
    "\n",
    "3. **Représentation du texte** :\n",
    "\n",
    "   Dans le contexte de la classification de spam, les données textuelles doivent être converties en un format numérique que l'algorithme peut comprendre. Cela se fait souvent à l'aide de techniques comme TF-IDF (Fréquence du terme-Fréquence inverse du document) ou la vectorisation de comptage.\n",
    "\n",
    "4. **Entraînement** :\n",
    "\n",
    "   Pendant la phase d'entraînement, l'algorithme apprend les probabilités nécessaires à la classification. Il calcule les probabilités de chaque classe (spam et non spam) ainsi que les probabilités de chaque caractéristique étant donné chaque classe.\n",
    "\n",
    "5. **Prédiction** :\n",
    "\n",
    "   Lors de la classification de nouvelles données (par exemple, un e-mail), l'algorithme calcule la probabilité qu'elles appartiennent à chaque classe en fonction des caractéristiques. Il sélectionne ensuite la classe avec la probabilité la plus élevée comme classe prédite.\n",
    "\n",
    "   $$P(\\text{Classe} = \\text{\"spam\"} | \\text{Caractéristiques}) \\propto P(\\text{\"spam\"}) \\times \\prod_{i=1}^n P(\\text{Caractéristique}_i | \\text{\"spam\"})$$\n",
    "\n",
    "   $$P(\\text{Classe} = \\text{\"non spam\"} | \\text{Caractéristiques}) \\propto P(\\text{\"non spam\"}) \\times \\prod_{i=1}^n P(\\text{Caractéristique}_i | \\text{\"non spam\"})$$\n",
    "\n",
    "6. **Lissage** :\n",
    "\n",
    "   Parfois, certains mots ou caractéristiques peuvent ne pas être présents dans les données d'entraînement pour une classe particulière. Cela peut conduire à des probabilités nulles, ce qui causerait des problèmes lors de la classification. Le lissage de Laplace ou d'autres techniques de lissage peuvent être utilisés pour gérer cela.\n",
    "\n",
    "7. **Évaluation** :\n",
    "\n",
    "   La performance du modèle est évaluée à l'aide de métriques telles que l'exactitude, la précision, le rappel et le score F1 sur un ensemble de validation ou de test distinct.\n",
    "\n",
    "N'oubliez pas, Naive Bayes est un algorithme relativement simple et ne surpasse pas toujours des modèles plus complexes. Cependant, il s'entraîne rapidement et peut servir de bon point de départ pour les tâches de classification de texte comme la détection de spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "## Importing Functions and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\nmadali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nmadali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#import pdb\n",
    "from nltk.corpus import stopwords, twitter_samples\n",
    "from nltk.stem.porter import  PorterStemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from os import getcwd\n",
    "#import w2_unittest\n",
    "\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenez les ensembles de tweets positifs et négatifs\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
    "\n",
    "# obtenez les ensembles de tweets positifs et négatifs\n",
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "train_x = train_pos + train_neg\n",
    "test_x = test_pos + test_neg\n",
    "\n",
    "# évitez les hypothèses sur la longueur de all_positive_tweets\n",
    "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
    "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1 - Traiter les données\n",
    "\n",
    "Pour tout projet d'apprentissage automatique, une fois que vous avez collecté les données, la première étape consiste à les traiter pour apporter des entrées utiles à votre modèle.\n",
    "- **Supprimer le bruit** : vous souhaiterez d'abord supprimer le bruit de vos données, c'est-à-dire supprimer les mots qui ne vous disent pas grand-chose sur le contenu. Ceux-ci incluent tous les mots courants comme « Je, vous, êtes, est, etc... » qui ne nous donneraient pas suffisamment d'informations sur le sentiment.\n",
    "\n",
    "- Nous supprimerons également les tickers boursiers, les symboles de retweet, les hyperliens et les hashtags, car ils ne peuvent pas vous donner beaucoup d'informations sur le sentiment.\n",
    "\n",
    "- Vous souhaitez également supprimer toute la ponctuation d'un tweet. La raison en est que nous voulons traiter les mots avec ou sans ponctuation comme le même mot, au lieu de traiter « heureux », « heureux ? », « heureux ! », « heureux » et « heureux ». comme des mots différents.\n",
    "\n",
    "- Enfin, vous souhaitez utiliser la recherche radicale pour ne suivre qu'une seule variation de chaque mot. En d’autres termes, nous traiterons « motivation », « motivé » et « motiver » de la même manière en les regroupant au sein du même radical « motiv- ».\n",
    "\n",
    "Nous vous avons donné la fonction `process_tweet` qui fait cela pour vous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,        strip_handles=True,reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  \n",
    "                word not in string.punctuation): \n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'great', 'day', ':)', 'good', 'morn']\n"
     ]
    }
   ],
   "source": [
    "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
    "\n",
    "# print cleaned tweet\n",
    "print(process_tweet(custom_tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 - Implémentation de vos fonctions d'assistance\n",
    "\n",
    "Pour vous aider à entraîner votre modèle bayésien naïf, vous devrez calculer un dictionnaire où les clés sont un tuple (mot, étiquette) et les valeurs sont la fréquence correspondante. Notez que les étiquettes que nous utiliserons ici sont 1 pour positif et 0 pour négatif.\n",
    "\n",
    "Vous implémenterez également une fonction d'aide à la recherche qui prend dans le dictionnaire « freqs », un mot et une étiquette (1 ou 0) et renvoie le nombre de fois que ce mot et ce tuple d'étiquette apparaissent dans la collection de tweets.\n",
    "\n",
    "Par exemple : étant donné une liste de tweets `[\"je suis plutôt excité\", \"vous êtes plutôt heureux\"]` et le label 1, la fonction renverra un dictionnaire contenant les paires clé-valeur suivantes :\n",
    "\n",
    "{\n",
    "     (\"plutôt\", 1): 2,\n",
    "     (\"heureux\", 1) : 1,\n",
    "     (\"exciter\", 1) : 1\n",
    "}\n",
    "\n",
    "- Remarquez comment pour chaque mot de la chaîne donnée, la même étiquette 1 est attribuée à chaque mot.\n",
    "- Notez que les mots \"je\" et \"suis\" ne sont pas enregistrés, car ils ont été supprimés par process_tweet car il s'agit d'un mot vide.\n",
    "- Remarquez comment le mot \"plutôt\" apparaît deux fois dans la liste des tweets, et sa valeur de comptage est donc 2.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_tweets(result, tweets, ys):\n",
    "    '''\n",
    "     Saisir:\n",
    "         résultat : un dictionnaire qui servira à mapper chaque paire à sa fréquence\n",
    "         tweets : une liste de tweets\n",
    "         ys : une liste correspondant au sentiment de chaque tweet (soit 0, soit 1)\n",
    "     Sortir:\n",
    "         résultat : un dictionnaire mappant chaque paire à sa fréquence\n",
    "     '''\n",
    "    \n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            # définit la clé, qui est le tuple de mots et d'étiquettes\n",
    "            pair = (word, y)\n",
    "            \n",
    "            # si la clé existe dans le dictionnaire, incrémente le décompte\n",
    "            if pair in result:\n",
    "                result[pair] += 1\n",
    "\n",
    "            # sinon, si la clé est nouvelle, ajoutez-la au dictionnaire et définissez le nombre sur 1\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('happi', 1): 1, ('trick', 0): 1, ('sad', 0): 1, ('tire', 0): 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tester votre fonction\n",
    "\n",
    "result = {}\n",
    "tweets = ['i am happy', 'i am tricked', 'i am sad', 'i am tired', 'i am tired']\n",
    "ys = [1, 0, 0, 0, 0]\n",
    "count_tweets(result, tweets, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2 - Entraînez votre modèle à l'aide de Naive Bayes\n",
    "\n",
    "Naive Bayes est un algorithme qui pourrait être utilisé pour l'analyse des sentiments. L'entraînement prend peu de temps et le temps de prédiction est également court.\n",
    "\n",
    "#### Alors, comment former un classificateur Naive Bayes ?\n",
    "- La première partie de la formation d'un classificateur bayésien naïf consiste à identifier le nombre de classes dont vous disposez.\n",
    "- Vous créerez une probabilité pour chaque classe.\n",
    "$P(D_{pos})$ est la probabilité que le document soit positif.\n",
    "$P(D_{neg})$ est la probabilité que le document soit négatif.\n",
    "Utilisez les formules comme suit et stockez les valeurs dans un dictionnaire :\n",
    "\n",
    "$$P(D_{pos}) = \\frac{D_{pos}}{D}\\tag{1}$$\n",
    "\n",
    "$$P(D_{nég}) = \\frac{D_{nég}}{D}\\tag{2}$$\n",
    "\n",
    "Où $D$ est le nombre total de documents, ou de tweets dans ce cas, $D_{pos}$ est le nombre total de tweets positifs et $D_{neg}$ est le nombre total de tweets négatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prior et Logprior\n",
    "\n",
    "La probabilité a priori représente la probabilité sous-jacente dans la population cible qu'un tweet soit positif ou négatif. En d’autres termes, si nous n’avions aucune information spécifique et si nous choisissions aveuglément un tweet parmi la population, quelle est la probabilité qu’il soit positif ou négatif ? C'est le \"prior\".\n",
    "\n",
    "Le prior est le rapport des probabilités $\\frac{P(D_{pos})}{P(D_{neg})}$.\n",
    "Nous pouvons prendre le journal du prior pour le redimensionner, et nous appellerons cela le logprior\n",
    "\n",
    "$$\\text{logprior} = journal \\left( \\frac{P(D_{pos})}{P(D_{neg})} \\right) = journal \\left( \\frac{D_{pos}}{D_ {nég}} \\right)$$.\n",
    "\n",
    "Notez que $log(\\frac{A}{B})$ est identique à $log(A) - log(B)$. Ainsi, le logprior peut également être calculé comme la différence entre deux journaux :\n",
    "\n",
    "$$\\text{logprior} = \\log (P(D_{pos})) - \\log (P(D_{neg})) = \\log (D_{pos}) - \\log (D_{neg})\\ balise{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilité positive et négative d'un mot\n",
    "Pour calculer la probabilité positive et la probabilité négative d'un mot spécifique du vocabulaire, nous utiliserons les entrées suivantes :\n",
    "\n",
    "- $freq_{pos}$ et $freq_{neg}$ sont les fréquences de ce mot spécifique dans la classe positive ou négative. En d’autres termes, la fréquence positive d’un mot est le nombre de fois où le mot est compté avec l’étiquette 1.\n",
    "- $N_{pos}$ et $N_{neg}$ sont respectivement le nombre total de mots positifs et négatifs pour tous les documents (pour tous les tweets).\n",
    "- $V$ est le nombre de mots uniques dans l'ensemble des documents, pour toutes les classes, qu'elles soient positives ou négatives.\n",
    "\n",
    "Nous les utiliserons pour calculer la probabilité positive et négative d'un mot spécifique en utilisant cette formule :\n",
    "\n",
    "$$ P(W_{pos}) = \\frac{freq_{pos} + 1}{N_{pos} + V}\\tag{4} $$\n",
    "$$ P(W_{nég}) = \\frac{freq_{nég} + 1}{N_{nég} + V}\\tag{5} $$\n",
    "\n",
    "Notez que nous ajoutons le \"+1\" au numérateur pour le lissage additif. Cet [article wiki](https://en.wikipedia.org/wiki/Additive_smoothing) en explique plus sur le lissage additif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enregistrer la probabilité\n",
    "Pour calculer la log-vraisemblance de ce même mot, nous pouvons implémenter les équations suivantes :\n",
    "\n",
    "$$\\text{loglikelihood} = \\log \\left(\\frac{P(W_{pos})}{P(W_{neg})} \\right)\\tag{6}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Créer un dictionnaire `freqs`\n",
    "- Étant donné votre fonction `count_tweets`, vous pouvez calculer un dictionnaire appelé `freqs` qui contient toutes les fréquences.\n",
    "- Dans ce dictionnaire `freqs`, la clé est le tuple (mot, label)\n",
    "- La valeur est le nombre de fois qu'elle est apparue.\n",
    "\n",
    "Nous utiliserons ce dictionnaire dans plusieurs parties de ce devoir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le dictionnaire de fréquences pour des utilisations ultérieures\n",
    "freqs = count_tweets({}, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "     Saisir:\n",
    "         freqs : dictionnaire de (mot, étiquette) à la fréquence d'apparition du mot\n",
    "         train_x : une liste de tweets\n",
    "         train_y : une liste de labels correspondant aux tweets (0,1)\n",
    "     Sortir:\n",
    "         logprior : le journal antérieur. (équation 3 ci-dessus)\n",
    "         logvraisemblance : le log de vraisemblance de votre équation naïve de Bayes. (équation 6 ci-dessus)\n",
    "     '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    \n",
    "\n",
    "    # calculer V, le nombre de mots uniques dans le vocabulaire\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "\n",
    "    # calculer N_pos, N_neg, V_pos, V_neg\n",
    "    N_pos = N_neg = 0    \n",
    "    for pair in freqs.keys():\n",
    "        # si le label est positif (supérieur à zéro)\n",
    "        if pair[1] > 0:\n",
    "\n",
    "            # Augmentez le nombre de mots positifs du nombre pour cette paire (mot, étiquette)\n",
    "            N_pos += freqs[pair]\n",
    "\n",
    "        # sinon, le label est négatif\n",
    "        else:\n",
    "\n",
    "            # incrémente le nombre de mots négatifs du nombre pour cette paire (mot, étiquette)\n",
    "            N_neg += freqs[pair]\n",
    "    \n",
    "    # Calculez D, le nombre de documents\n",
    "    D = train_y.shape[0]\n",
    "\n",
    "    # Calculez D, le nombre de documents\n",
    "    D_pos = train_y[train_y == 1].shape[0]\n",
    "\n",
    "    # Calculez D_neg, le nombre de documents négatifs\n",
    "    D_neg = train_y[train_y == 0].shape[0]\n",
    "\n",
    "    # Calculer le logprior\n",
    "    logprior = np.log(D_pos/D_neg)\n",
    "    \n",
    "    # Pour chaque mot du vocabulaire...\n",
    "    for word in vocab:\n",
    "        # obtenir la fréquence positive et négative du mot\n",
    "        freq_pos = freqs.get((word, 1), 0)\n",
    "        freq_neg = freqs.get((word, 0), 0)\n",
    "\n",
    "        # calculer la probabilité que chaque mot soit positif et négatif\n",
    "        p_w_pos = (freq_pos+1)/(N_pos+V)\n",
    "        p_w_neg = (freq_neg+1)/(N_neg+V)\n",
    "\n",
    "        # calculer la vraisemblance du mot\n",
    "        loglikelihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "\n",
    "   \n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "9086\n"
     ]
    }
   ],
   "source": [
    "# UNQ_C3 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 – Testez votre Naive Bayes\n",
    "\n",
    "Maintenant que nous avons le « logprior » et le « loglikelihood », nous pouvons tester la fonction naïve de Bayes en faisant des prédictions sur certains tweets !\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercice 3 - naive_bayes_predict\n",
    "Implémentez `naive_bayes_predict`.\n",
    "\n",
    "**Instructions**:\n",
    "Implémentez la fonction `naive_bayes_predict` pour faire des prédictions sur les tweets.\n",
    "* La fonction prend en compte le « tweet », le « logprior », le « loglikelihood ».\n",
    "* Il renvoie la probabilité que le tweet appartienne à la classe positive ou négative.\n",
    "* Pour chaque tweet, résumez les log-vraisemblances de chaque mot du tweet.\n",
    "* Ajoutez également le logprior à cette somme pour obtenir le sentiment prévu de ce tweet.\n",
    "\n",
    "$$ p = logprior + \\sum_i^N (loglikelihood_i)$$\n",
    "\n",
    "#### Note\n",
    "Notez que nous calculons le prior à partir des données de formation et que les données de formation sont réparties également entre les étiquettes positives et négatives (4 000 tweets positifs et 4 000 négatifs). Cela signifie que le rapport du positif au négatif est de 1 et que le logprior est de 0.\n",
    "\n",
    "La valeur de 0,0 signifie que lorsque nous ajoutons le logprior au log de vraisemblance, nous ajoutons simplement zéro au log de vraisemblance. Cependant, n'oubliez pas d'inclure le logprior, car chaque fois que les données ne sont pas parfaitement équilibrées, le logprior sera une valeur non nulle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "    '''\n",
    "     Saisir:\n",
    "         tweet : une chaîne\n",
    "         logprior : un nombre\n",
    "         logvraisemblance : un dictionnaire de mots correspondant à des nombres\n",
    "     Sortir:\n",
    "         p : la somme de toutes les logliklihoods de chaque mot du tweet (s'il est trouvé dans le dictionnaire) + logprior (un nombre)\n",
    "\n",
    "     '''\n",
    "    \n",
    "    # traiter le tweet pour obtenir une liste de mots\n",
    "    word_l = process_tweet(tweet)\n",
    "\n",
    "    # initialiser la probabilité à zéro\n",
    "    p = 0\n",
    "\n",
    "    # ajouter le logprior\n",
    "    p += logprior\n",
    "\n",
    "    for word in word_l:\n",
    "\n",
    "        # vérifie si le mot existe dans le dictionnaire log-vraisemblance\n",
    "        if word in loglikelihood:\n",
    "            # ajoute la probabilité logarithmique de ce mot à la probabilité\n",
    "            p += loglikelihood[word]\n",
    "\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 1.5736965101941158\n"
     ]
    }
   ],
   "source": [
    "my_tweet = 'She smiled.'\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is -0.14907008754698764\n"
     ]
    }
   ],
   "source": [
    "# Experiment with your own tweet.\n",
    "my_tweet = 'He laughed.'\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-4'></a>\n",
    "### Exercice 4 - test_naive_bayes\n",
    "Implémentez test_naive_bayes.\n",
    "\n",
    "**Instructions**:\n",
    "* Implémentez `test_naive_bayes` pour vérifier l'exactitude de vos prédictions.\n",
    "* La fonction prend en compte vos `test_x`, `test_y`, log_prior et loglikelihood\n",
    "* Il renvoie la précision de votre modèle.\n",
    "* Tout d'abord, utilisez la fonction `naive_bayes_predict` pour faire des prédictions pour chaque tweet dans text_x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood, naive_bayes_predict=naive_bayes_predict):\n",
    "    \"\"\"\n",
    "         Saisir:\n",
    "             test_x : Une liste de tweets\n",
    "             test_y : les labels correspondants pour la liste des tweets\n",
    "             logprior : le logprior\n",
    "             logvraisemblance : un dictionnaire avec les logvraisemblances pour chaque mot\n",
    "         Sortir:\n",
    "             précision : (nombre de tweets classés correctement)/(nombre total de tweets)\n",
    "    \"\"\"\n",
    "    accuracy = 0  # return this properly\n",
    "\n",
    "    \n",
    "    y_hats = []\n",
    "    for tweet in test_x:\n",
    "        # si la prédiction est > 0\n",
    "        if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
    "            # la classe prédite est 1\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            # sinon la classe prédite est 0\n",
    "            y_hat_i = 0\n",
    "\n",
    "        # ajoute la classe prédite à la liste y_hats\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    # l'erreur est la moyenne des valeurs absolues des différences entre y_hats et test_y\n",
    "    error = sum(abs(test_y-y_hats))/len(test_y)\n",
    "\n",
    "    # La précision est de 1 moins l'erreur\n",
    "    accuracy = 1-error\n",
    "\n",
    "   \n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision naïve de Bayes = 0.9940\n"
     ]
    }
   ],
   "source": [
    "print(\"Précision naïve de Bayes = %0.4f\" % (test_naive_bayes(test_x, test_y, logprior, loglikelihood)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy -> 2.15\n",
      "I am bad -> -1.29\n",
      "this movie should have been great. -> 2.14\n",
      "great -> 2.14\n",
      "great great -> 4.28\n",
      "great great great -> 6.41\n",
      "great great great great -> 8.55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
    "    p\n",
    "    p = naive_bayes_predict(tweet, logprior, loglikelihood)\n",
    "#     print(f'{tweet} -> {p:.2f} ({p_category})')\n",
    "    print(f'{tweet} -> {p:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.802285344803796"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N'hésitez pas à vérifier le sentiment de votre propre tweet ci-dessous\n",
    "my_tweet = 'you are bad :('\n",
    "naive_bayes_predict(my_tweet, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Filtrer les mots par rapport entre les nombres positifs et négatifs\n",
    "\n",
    "- Certains mots ont des comptes plus positifs que d'autres et peuvent être considérés comme « plus positifs ». De même, certains mots peuvent être considérés comme plus négatifs que d’autres.\n",
    "- Une façon pour nous de définir le niveau de positivité ou de négativité, sans calculer le log de vraisemblance, est de comparer la fréquence positive à la fréquence négative du mot.\n",
    "     - Notez que nous pouvons également utiliser les calculs du log de vraisemblance pour comparer la positivité ou la négativité relative des mots.\n",
    "- Nous pouvons calculer le rapport des fréquences positives aux fréquences négatives d'un mot.\n",
    "- Une fois que nous sommes capables de calculer ces ratios, nous pouvons également filtrer un sous-ensemble de mots qui ont un ratio minimum de positivité/négativité ou supérieur.\n",
    "- De même, on peut également filtrer un sous-ensemble de mots qui ont un rapport positivité/négativité maximum ou inférieur (mots au moins aussi négatifs, voire plus négatifs qu'un seuil donné).\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### Exercice 5 - get_ratio\n",
    "Implémentez get_ratio.\n",
    "\n",
    "- Étant donné le dictionnaire de fréquences de mots et d'un mot particulier, utilisez `lookup(freqs,word,1)` pour obtenir le nombre positif du mot.\n",
    "- De même, utilisez la fonction « recherche » pour obtenir le nombre négatif de ce mot.\n",
    "- Calculer le rapport des comptes positifs divisés par les comptes négatifs\n",
    "\n",
    "$$ ratio = \\frac{\\text{pos_words} + 1}{\\text{neg_words} + 1} $$\n",
    "\n",
    "Où pos_words et neg_words correspondent à la fréquence des mots dans leurs classes respectives.\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>Words</b>\n",
    "        </td>\n",
    "        <td>\n",
    "        Positive word count\n",
    "        </td>\n",
    "         <td>\n",
    "        Negative Word Count\n",
    "        </td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        glad\n",
    "        </td>\n",
    "         <td>\n",
    "        41\n",
    "        </td>\n",
    "    <td>\n",
    "        2\n",
    "        </td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        arriv\n",
    "        </td>\n",
    "         <td>\n",
    "        57\n",
    "        </td>\n",
    "    <td>\n",
    "        4\n",
    "        </td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        :(\n",
    "        </td>\n",
    "         <td>\n",
    "        1\n",
    "        </td>\n",
    "    <td>\n",
    "        3663\n",
    "        </td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "        :-(\n",
    "        </td>\n",
    "         <td>\n",
    "        0\n",
    "        </td>\n",
    "    <td>\n",
    "        378\n",
    "        </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def lookup(freqs, word, label):\n",
    "    '''\n",
    "     Saisir:\n",
    "         freqs : un dictionnaire avec la fréquence de chaque paire (ou tuple)\n",
    "         mot : le mot à rechercher\n",
    "         label : le label correspondant au mot\n",
    "     Sortir:\n",
    "         n : le nombre de fois que le mot avec son étiquette correspondante apparaît.\n",
    "     '''\n",
    "    n = 0  # freqs.get((word, label), 0)\n",
    "\n",
    "    pair = (word, label)\n",
    "    if (pair in freqs):\n",
    "        n = freqs[pair]\n",
    "\n",
    "    return n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_ratio(freqs, word):\n",
    "    '''\n",
    "     Saisir:\n",
    "         freqs : dictionnaire contenant les mots\n",
    "\n",
    "     Sortie : un dictionnaire avec les clés « positif », « négatif » et « ratio ».\n",
    "         Exemple : {'positif' : 10, 'négatif' : 20, 'rapport' : 0,5}\n",
    "     '''\n",
    "    pos_neg_ratio = {'positive': 0, 'negative': 0, 'ratio': 0.0}\n",
    "\n",
    "    # utilisez lookup() pour trouver les nombres positifs pour le mot (indiqué par l'entier 1)\n",
    "    pos_neg_ratio['positive'] = lookup(freqs, word, 1)\n",
    "    \n",
    "    # utilisez lookup() pour trouver les nombres négatifs pour le mot (indiqué par l'entier 0)\n",
    "    pos_neg_ratio['negative'] = lookup(freqs, word, 0)\n",
    "    \n",
    "    # calculer le rapport entre les nombres positifs et négatifs pour le mot\n",
    "    pos_neg_ratio['ratio'] = (pos_neg_ratio['positive']+1) / (pos_neg_ratio['negative']+1)\n",
    "\n",
    "    return pos_neg_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': 161, 'negative': 18, 'ratio': 8.526315789473685}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ratio(freqs, 'happi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-6'></a>\n",
    "### Exercice 6 - get_words_by_threshold\n",
    "Implémenter get_words_by_threshold(freqs,label,threshold)\n",
    "\n",
    "* Si nous définissons l'étiquette sur 1, alors nous rechercherons tous les mots dont le seuil positif/négatif est au moins aussi élevé que ce seuil, ou supérieur.\n",
    "* Si nous définissons l'étiquette sur 0, alors nous rechercherons tous les mots dont le seuil positif/négatif est au plus aussi bas que le seuil donné, ou inférieur.\n",
    "* Utilisez la fonction `get_ratio` pour obtenir un dictionnaire contenant le nombre positif, le nombre négatif et le rapport des comptes positifs aux négatifs.\n",
    "* Ajoutez le dictionnaire `get_ratio` dans un autre dictionnaire, où la clé est le mot et la valeur est le dictionnaire `pos_neg_ratio` qui est renvoyé par la fonction `get_ratio`.\n",
    "Un exemple de paire clé-valeur aurait cette structure :\n",
    "```\n",
    "{'heureux' :\n",
    "     {'positif' : 10, 'négatif' : 20, 'rapport' : 0,524}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_words_by_threshold(freqs, label, threshold, get_ratio=get_ratio):\n",
    "    '''\n",
    "     Saisir:\n",
    "         fréquences : dictionnaire de mots\n",
    "         étiquette : 1 pour positif, 0 pour négatif\n",
    "         seuil : rapport qui sera utilisé comme seuil pour inclure un mot dans le dictionnaire renvoyé\n",
    "     Sortir:\n",
    "         word_list : dictionnaire contenant le mot et des informations sur son nombre positif, son nombre négatif et le rapport entre ses nombres positifs et négatifs.\n",
    "         exemple de paire clé-valeur :\n",
    "         {'heureux' :\n",
    "             {'positif' : 10, 'négatif' : 20, 'rapport' : 0,5}\n",
    "         }\n",
    "     '''\n",
    "    word_list = {}\n",
    "\n",
    "    for key in freqs.keys():\n",
    "        word, _ = key\n",
    "\n",
    "        # obtenir le rapport positif/négatif pour un mot\n",
    "        pos_neg_ratio = get_ratio(freqs, word)\n",
    "\n",
    "        # si le label est 1 et que le ratio est supérieur ou égal au seuil...\n",
    "        if label == 1 and pos_neg_ratio['ratio'] >= threshold:\n",
    "        \n",
    "            # Ajoutez le pos_neg_ratio au dictionnaire\n",
    "            word_list[word] = pos_neg_ratio\n",
    "\n",
    "        # Si le label est 0 et que le pos_neg_ratio est inférieur ou égal au seuil...\n",
    "        elif label == 0 and pos_neg_ratio['ratio'] <= threshold:\n",
    "        \n",
    "            # Ajoutez le pos_neg_ratio au dictionnaire\n",
    "            word_list[word] = pos_neg_ratio\n",
    "\n",
    "        # sinon, ne pas inclure ce mot dans la liste (ne rien faire)\n",
    "\n",
    "   \n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{':(': {'positive': 1, 'negative': 3663, 'ratio': 0.0005458515283842794},\n",
       " ':-(': {'positive': 0, 'negative': 378, 'ratio': 0.002638522427440633},\n",
       " 'zayniscomingbackonjuli': {'positive': 0, 'negative': 19, 'ratio': 0.05},\n",
       " '26': {'positive': 0, 'negative': 20, 'ratio': 0.047619047619047616},\n",
       " '>:(': {'positive': 0, 'negative': 43, 'ratio': 0.022727272727272728},\n",
       " 'lost': {'positive': 0, 'negative': 19, 'ratio': 0.05},\n",
       " '♛': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996},\n",
       " '》': {'positive': 0, 'negative': 210, 'ratio': 0.004739336492890996},\n",
       " 'beli̇ev': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'wi̇ll': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'justi̇n': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'ｓｅｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776},\n",
       " 'ｍｅ': {'positive': 0, 'negative': 35, 'ratio': 0.027777777777777776}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trouver des mots négatifs égaux ou inférieurs à un seuil\n",
    "get_words_by_threshold(freqs, label=0, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'followfriday': {'positive': 23, 'negative': 0, 'ratio': 24.0},\n",
       " 'commun': {'positive': 27, 'negative': 1, 'ratio': 14.0},\n",
       " ':)': {'positive': 2847, 'negative': 2, 'ratio': 949.3333333333334},\n",
       " 'flipkartfashionfriday': {'positive': 16, 'negative': 0, 'ratio': 17.0},\n",
       " ':d': {'positive': 498, 'negative': 0, 'ratio': 499.0},\n",
       " ':p': {'positive': 104, 'negative': 0, 'ratio': 105.0},\n",
       " 'influenc': {'positive': 16, 'negative': 0, 'ratio': 17.0},\n",
       " ':-)': {'positive': 543, 'negative': 0, 'ratio': 544.0},\n",
       " \"here'\": {'positive': 20, 'negative': 0, 'ratio': 21.0},\n",
       " 'youth': {'positive': 14, 'negative': 0, 'ratio': 15.0},\n",
       " 'bam': {'positive': 44, 'negative': 0, 'ratio': 45.0},\n",
       " 'warsaw': {'positive': 44, 'negative': 0, 'ratio': 45.0},\n",
       " 'shout': {'positive': 11, 'negative': 0, 'ratio': 12.0},\n",
       " ';)': {'positive': 22, 'negative': 0, 'ratio': 23.0},\n",
       " 'stat': {'positive': 51, 'negative': 0, 'ratio': 52.0},\n",
       " 'arriv': {'positive': 57, 'negative': 4, 'ratio': 11.6},\n",
       " 'via': {'positive': 60, 'negative': 1, 'ratio': 30.5},\n",
       " 'glad': {'positive': 41, 'negative': 2, 'ratio': 14.0},\n",
       " 'blog': {'positive': 27, 'negative': 0, 'ratio': 28.0},\n",
       " 'fav': {'positive': 11, 'negative': 0, 'ratio': 12.0},\n",
       " 'fback': {'positive': 26, 'negative': 0, 'ratio': 27.0},\n",
       " 'pleasur': {'positive': 10, 'negative': 0, 'ratio': 11.0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trouver des mots positifs au niveau ou au-dessus d'un seuil\n",
    "get_words_by_threshold(freqs, label=1, threshold=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez la différence entre les ratios positifs et négatifs. Les émojis comme :( et les mots comme « moi » ont tendance à avoir une connotation négative. D'autres mots comme heureux, communauté, arrive, ont tendance à être trouvés dans les tweets positifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Analyse des erreurs\n",
    "\n",
    "Dans cette partie, vous verrez quelques tweets que votre modèle a mal classés. Pourquoi pensez-vous que les erreurs de classification se sont produites ? Votre modèle bayésien naïf a-t-il formulé des hypothèses ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet prédit par la vérité\n",
      "1\t0.00\tb''\n",
      "1\t0.00\tb'truli later move know queen bee upward bound movingonup'\n",
      "1\t0.00\tb'new report talk burn calori cold work harder warm feel better weather :p'\n",
      "1\t0.00\tb'harri niall 94 harri born ik stupid wanna chang :d'\n",
      "1\t0.00\tb''\n",
      "1\t0.00\tb''\n",
      "1\t0.00\tb'park get sunlight'\n",
      "1\t0.00\tb'uff itna miss karhi thi ap :p'\n",
      "0\t1.00\tb'hello info possibl interest jonatha close join beti :( great'\n",
      "0\t1.00\tb'u prob fun david'\n",
      "0\t1.00\tb'pat jay'\n",
      "0\t1.00\tb'whatev stil l young >:-('\n"
     ]
    }
   ],
   "source": [
    "# Une analyse d'erreur effectuée pour vous\n",
    "print('Tweet prédit par la vérité')\n",
    "for x, y in zip(test_x, test_y):\n",
    "    y_hat = naive_bayes_predict(x, logprior, loglikelihood)\n",
    "    if y != (np.sign(y_hat) > 0):\n",
    "        print('%d\\t%0.2f\\t%s' % (y, np.sign(y_hat) > 0, ' '.join(\n",
    "            process_tweet(x)).encode('ascii', 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Prédisez avec votre propre Tweet\n",
    "\n",
    "Dans cette partie, vous pouvez prédire le sentiment de votre propre tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.573774904705935\n"
     ]
    }
   ],
   "source": [
    "# Testez avec votre propre tweet - n'hésitez pas à modifier `my_tweet`\n",
    "my_tweet = 'I am happy because I am learning :)'\n",
    "\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
